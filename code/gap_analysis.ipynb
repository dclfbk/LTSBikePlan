{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/images\"\n",
    "city_name = \"Trento\"\n",
    "\n",
    "# Create the path for the new folder\n",
    "city_folder_path = os.path.join(base_path, city_name)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(city_folder_path):\n",
    "    os.makedirs(city_folder_path)\n",
    "\n",
    "# Load data\n",
    "filepath = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/Trento_lts.graphml\"\n",
    "G_lts = ox.load_graphml(filepath)\n",
    "G_lts = ox.project_graph(G_lts, to_crs='EPSG:4326')\n",
    "\n",
    "# 1. Filter the Graph\n",
    "low_stress_edges = [(u, v, k, data) for u, v, k, data in G_lts.edges(keys=True, data=True) if 'lts' in data and data['lts'] in ['1', '2']]\n",
    "low_stress_nodes = [node for node, data in G_lts.nodes(data=True) if 'lts' in data and data['lts'] in ['1', '2']]\n",
    "\n",
    "# Create a new graph with only low-stress edges and nodes\n",
    "G_low_stress = nx.MultiDiGraph()\n",
    "G_low_stress.add_nodes_from(low_stress_nodes)\n",
    "G_low_stress.add_edges_from(low_stress_edges)\n",
    "\n",
    "# 2. Find Connected Components\n",
    "# Convert the graph to undirected for finding connected components\n",
    "G_low_stress_undirected = G_low_stress.to_undirected()\n",
    "connected_components = list(nx.connected_components(G_low_stress_undirected))\n",
    "\n",
    "# Sort the connected components by size (largest to smallest) and select the top 10\n",
    "top_components = sorted(connected_components, key=len, reverse=True)[:10]\n",
    "\n",
    "# Assign a unique color to each of the top 10 connected components\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(top_components)))\n",
    "component_colors = {}\n",
    "component_patches = [] \n",
    "for color, component in zip(colors, top_components):\n",
    "    for node in component:\n",
    "        component_colors[node] = color\n",
    "    component_patches.append(mpatches.Patch(color=color, label=f'Component {len(component_patches) + 1}'))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Get node positions using osmnx\n",
    "node_positions = {node: (data['x'], data['y']) for node, data in G_lts.nodes(data=True)}\n",
    "\n",
    "# Plot edges with their respective colors\n",
    "edge_colors = ['black' if ('lts' in data and data['lts'] in ['3', '4']) else 'lightgray' for u, v, k, data in G_lts.edges(keys=True, data=True)]\n",
    "ox.plot_graph(G_lts, ax=ax, node_size=0, edge_color=edge_colors, edge_linewidth=1.5, edge_alpha=0.7, show=False)\n",
    "\n",
    "# Highlight the top 10 connected components with unique colors\n",
    "for node, color in component_colors.items():\n",
    "    nx.draw_networkx_nodes(G_lts, pos=node_positions, nodelist=[node], node_color=[color], node_size=50, ax=ax)\n",
    "\n",
    "# Add legend for the top 10 connected components\n",
    "ax.legend(handles=component_patches, loc='upper right', title='Top 10 Connected Components')\n",
    "file_path = os.path.join(city_folder_path, 'Top10connectedcomponents_plot.png')\n",
    "plt.savefig(file_path)\n",
    "plt.show()\n",
    "\n",
    "# 3. Identify Gaps\n",
    "# Print the gaps between connected components\n",
    "for i, component in enumerate(connected_components[:10]):\n",
    "    print(f\"Connected Component {i+1}: {component}\")\n",
    "\n",
    "# Optionally, visualize the graph\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "colors = ['red' if ('lts' in data and data['lts'] in ['3', '4']) else 'green' for u, v, k, data in G_lts.edges(keys=True, data=True)]\n",
    "ox.plot_graph(G_lts, ax=ax, node_size=0, edge_color=colors, edge_linewidth=1.5, edge_alpha=0.7, show=False)\n",
    "\n",
    "# Add legend to the same plot\n",
    "red_patch = mpatches.Patch(color='red', label='High Stress')\n",
    "green_patch = mpatches.Patch(color='green', label='Low Stress')\n",
    "ax.legend(handles=[red_patch, green_patch], loc='upper right')\n",
    "file_path = os.path.join(city_folder_path, 'highlowstresscomponents_plot.png')\n",
    "plt.savefig(file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDCP procedure - Identify\n",
    "\n",
    "# 1. Identify Contact Nodes\n",
    "contact_nodes = []\n",
    "for node, data in G_lts.nodes(data=True):\n",
    "    adjacent_edges = list(G_lts.out_edges(node, data=True))\n",
    "    lts_values = [data['lts'] for _, _, data in adjacent_edges]\n",
    "    if ('1' in lts_values or '2' in lts_values) and ('3' in lts_values or '4' in lts_values):\n",
    "        contact_nodes.append(node)\n",
    "\n",
    "print(contact_nodes)\n",
    "\n",
    "# 2. Identify High-Stress Paths using Dijkstra all-pair shortest path algorithm\n",
    "high_stress_paths = {}\n",
    "for source in contact_nodes:\n",
    "    lengths, paths = nx.single_source_dijkstra(G_lts, source, weight='length')\n",
    "    for target, path in paths.items():\n",
    "        if target in contact_nodes and source != target:\n",
    "            # Initialize an empty list to store lts values for the current path\n",
    "            lts_values = []\n",
    "\n",
    "            # Iterate over each pair of nodes in the path\n",
    "            for i in range(len(path) - 1):\n",
    "                u, v = path[i], path[i + 1]\n",
    "\n",
    "                # Check each edge between u and v\n",
    "                for k, data in G_lts[u][v].items():\n",
    "                    if data['lts'] != '0':  # Exclude edges with lts value of '0'\n",
    "                        lts_values.append(data['lts'])\n",
    "                        break  # Assuming you want to consider only the first matching edge\n",
    "\n",
    "            # Check if all lts values are in ['3', '4']\n",
    "            if all(lts in ['3', '4'] for lts in lts_values):\n",
    "                high_stress_paths[(source, target)] = path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter Shortest High-Stress Paths\n",
    "shortest_high_stress_paths = {}\n",
    "for (source, target), path in high_stress_paths.items():\n",
    "    if (target, source) not in shortest_high_stress_paths:\n",
    "        if (target, source) in high_stress_paths:\n",
    "            if len(path) < len(high_stress_paths[(target, source)]):\n",
    "                shortest_high_stress_paths[(source, target)] = path\n",
    "        else:\n",
    "            shortest_high_stress_paths[(source, target)] = path\n",
    "\n",
    "#Print the shortest high-stress paths\n",
    "for (source, target), path in shortest_high_stress_paths.items():\n",
    "    print(f\"Gap from {source} to {target}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the dictionary keys (which are tuples) to strings\n",
    "shortest_high_stress_paths_str_keys = {str(k): v for k, v in shortest_high_stress_paths.items()}\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open('../data/shortest_high_stress_paths.json', 'w') as file:\n",
    "    json.dump(shortest_high_stress_paths_str_keys, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization edges and gaps contact nodes\n",
    "\n",
    "# Create a list of edge colors for the entire graph\n",
    "edge_colors = {}\n",
    "for u, v, k, data in G_lts.edges(keys=True, data=True):\n",
    "    edge_key = (u, v, k)\n",
    "    if 'lts' in data:\n",
    "        if data['lts'] in ['1', '2']:\n",
    "            edge_colors[edge_key] = 'green'\n",
    "        elif data['lts'] in ['3', '4']:\n",
    "            edge_colors[edge_key] = 'red'\n",
    "        else:\n",
    "            edge_colors[edge_key] = 'gray'\n",
    "    else:\n",
    "        edge_colors[edge_key] = 'gray'\n",
    "\n",
    "# Highlight the gaps in blue\n",
    "for (source, target), path in high_stress_paths.items():\n",
    "    for i in range(len(path) - 1):\n",
    "        u, v = path[i], path[i + 1]\n",
    "        for k in G_lts[u][v]:\n",
    "            edge_key = (u, v, k)\n",
    "            edge_colors[edge_key] = 'blue'\n",
    "\n",
    "# Plot the graph with highlighted gaps\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "edge_color_list = [edge_colors[edge] for edge in G_lts.edges(keys=True)]\n",
    "ox.plot_graph(G_lts, ax=ax, node_size=0, edge_color=edge_color_list, edge_linewidth=0.5, edge_alpha=0.7, show=False)\n",
    "\n",
    "# Add legend to the same plot\n",
    "red_patch = mpatches.Patch(color='red', label='High Stress')\n",
    "green_patch = mpatches.Patch(color='green', label='Low Stress')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Gap')\n",
    "ax.legend(handles=[red_patch, green_patch, blue_patch], loc='upper right')\n",
    "file_path = os.path.join(city_folder_path, 'gaps_plot.png')\n",
    "plt.savefig(file_path)\n",
    "plt.show()\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Get node positions using osmnx\n",
    "node_positions = {node: (data['x'], data['y']) for node, data in G_lts.nodes(data=True)}\n",
    "\n",
    "# Plot edges with their respective colors\n",
    "colors = ['red' if ('lts' in data and data['lts'] in ['3', '4']) else 'green' for u, v, k, data in G_lts.edges(keys=True, data=True)]\n",
    "ox.plot_graph(G_lts, ax=ax, node_size=0, edge_color=colors, edge_linewidth=1.5, edge_alpha=0.7, show=False)\n",
    "\n",
    "# Highlight contact nodes\n",
    "contact_node_colors = {node: 'blue' for node in contact_nodes}\n",
    "nx.draw_networkx_nodes(G_lts, pos=node_positions, nodelist=contact_node_colors.keys(), node_color=list(contact_node_colors.values()), node_size=20, ax=ax)\n",
    "\n",
    "# Add legend to the same plot\n",
    "red_patch = mpatches.Patch(color='red', label='High Stress')\n",
    "green_patch = mpatches.Patch(color='green', label='Low Stress')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Contact Node')\n",
    "ax.legend(handles=[red_patch, green_patch, blue_patch], loc='upper right')\n",
    "file_path = os.path.join(city_folder_path, 'contact_nodes_plot.png')\n",
    "plt.savefig(file_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already run the previous code blocks\n",
    "\n",
    "# 4. Calculate Detour Factor and Filter Gaps\n",
    "D_min = 2\n",
    "filtered_gaps = {}\n",
    "\n",
    "for (source, target), high_stress_path in shortest_high_stress_paths.items():\n",
    "    # Calculate the shortest path distance on the low stress network (d_prot(g))\n",
    "    try:\n",
    "        d_lowstress_g = nx.shortest_path_length(G_low_stress, source=source, target=target, weight='length')\n",
    "    except nx.NetworkXNoPath:\n",
    "        # If there's no path in the low stress network, we can't calculate a detour factor\n",
    "        continue\n",
    "    \n",
    "    # Calculate the shortest path distance on the entire street network (d_all(g))\n",
    "    d_all_g = nx.shortest_path_length(G_lts, source=source, target=target, weight='length')\n",
    "    \n",
    "    # Calculate the detour factor (D(g))\n",
    "    D_g = d_lowstress_g / d_all_g\n",
    "    \n",
    "    # Filter gaps with D(g) less than D_min\n",
    "    if D_g >= D_min:\n",
    "        filtered_gaps[(source, target)] = high_stress_path\n",
    "\n",
    "#Print the filtered gaps\n",
    "# for (source, target), path in filtered_gaps.items():\n",
    "#     print(f\"Filtered Gap from {source} to {target}: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the dictionary keys to strings because JSON does not support tuple keys\n",
    "data_str_keys = {str(k): v for k, v in filtered_gaps.items()}\n",
    "\n",
    "# Write to file\n",
    "with open('../data/filtered_gaps.json', 'w') as file:\n",
    "    json.dump(data_str_keys, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive impact consists in reducing the number of meters that cyclists have to ride in the same space as motorized traffic, so with high stress.  Therefore, the aim is to prioritizing gaps that lie on the most commonly taken bicycle routes.\n",
    "\n",
    "To prioritize these gaps, the authors suggest considering three main questions:\n",
    "- Centrality: How central is the missing link in the network?\n",
    "- Cost: How much does it cost to close this gap?\n",
    "- Benefit: How many citizens will benefit from closing it? (The \"benefit\" of closing a gap is quantified by the reduction in the number of meters that cyclists have to ride in mixed traffic with motorized vehicles)\n",
    "  \n",
    "To estimate the most commonly used bicycle routes (and thus identify the most important gaps), the authors of IDPC use a metric called **\"link betweenness centrality weighted by gap length.\"** This metric is based on the assumption that cyclists will choose the shortest path between their origin and destination. The betweenness centrality of a link in the network indicates how often that link is used in the shortest paths between all pairs of nodes in the network. By weighting this centrality by the length of the gap, they can estimate the total number of meters cycled in mixed traffic for each gap.\n",
    "\n",
    "*In order to apply this rationale, we estimated the number of cyclists on each link, i.e. the bicycle traffic flow through the network, based on the network topology, using betweenness centrality. Betweenness centrality, derived from an all-pair shortest path algorithm, is the most basic proxy for traffic demand. It assumes that for each possible origin-destination combination, there is one “cyclist unit” making their way through the network, always choosing the shortest possible path between origin and destination. Then the number of cyclists that use a specific link on their way through the network, divided by the total number of cyclists on the network, will yield the fraction of cyclists that we expect to find on this link. Thus, the betweenness centrality indicates how “central” or relevant a link is for the flow of cyclists through the whole network*\n",
    "\n",
    "The authors also introduce a locality parameter (𝜆) to account for the **\"network edge effect\"**, which biases centrality metrics towards the center of the network. By setting 𝜆 to a finite value (2500m in their case for Copenhagen district diameter), they can focus on gaps that are relevant for local flows within neighborhoods or districts, rather than the entire city.\n",
    "\n",
    "Finally, they calculate a **\"gap closure benefit\" (B*(g))** for each gap, which is the product of the betweenness centrality and the length of the gap. This metric represents the total number of expected meters cycled on the gap. They then divide this by the total length of the gap to get a measure of the expected meters cycled per investment unit (B(g)), which they use to prioritize gaps for closure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDCP procedure - Prioritize\n",
    "\n",
    "# 5. Calculate Betweenness Centrality with Locality Parameter λ\n",
    "# lambda_ = 1000  Set the locality parameter lambda (𝜆) to 2500 meters in Copenhagen\n",
    "lambda_ = 2400 #Trento\n",
    "# Custom function to compute betweenness centrality with locality parameter λ\n",
    "def localized_betweenness_centrality(G, lambda_, weight='length'):\n",
    "    node_local_betweenness = collections.defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        # Compute all shortest paths from the node within the locality parameter λ\n",
    "        lengths, paths = nx.single_source_dijkstra(G, node, cutoff=lambda_, weight=weight)\n",
    "        for target, path in paths.items():\n",
    "            if target != node:  # Exclude the node itself\n",
    "                for path_node in path[1:-1]:  # Exclude the source and target nodes\n",
    "                    node_local_betweenness[path_node] += 1\n",
    "    \n",
    "    # Normalize the betweenness centrality values (big cities)\n",
    "    # norm_factor = 1 / ((len(G.nodes()) - 1) * (len(G.nodes()) - 2))\n",
    "    # node_local_betweenness = {node: value * norm_factor for node, value in node_local_betweenness.items()}\n",
    "\n",
    "    # Normalize the betweenness centrality values (town/village scenario)\n",
    "    norm_factor = 1 / (len(G.nodes()) - 1)\n",
    "    node_local_betweenness = {node: value * norm_factor for node, value in node_local_betweenness.items()}\n",
    "\n",
    "    return node_local_betweenness\n",
    "\n",
    "# Compute betweenness centrality for all nodes in the network with locality parameter λ\n",
    "node_betweenness = localized_betweenness_centrality(G_lts, lambda_, weight='length')\n",
    "\n",
    "# 6. Estimate Bicycle Traffic Flow and Compute Benefit Metric with Cost-Efficiency\n",
    "gap_closure_benefits = {}\n",
    "\n",
    "for (source, target), path in filtered_gaps.items():\n",
    "    # Total length of the gap (L(g))\n",
    "    L_g = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        u, v = path[i], path[i + 1]\n",
    "        # Use the first edge key if there are multiple edges between u and v\n",
    "        edge_key = list(G_lts[u][v])[0] \n",
    "        L_g += G_lts[u][v][edge_key]['length']\n",
    "    \n",
    "    # Betweenness centrality for the gap (c_lambda(l))\n",
    "    c_lambda_l = sum(node_betweenness.get(node, 0) for node in path)  # Use .get() to handle missing nodes\n",
    "    \n",
    "    # Total number of expected meters cycled on this gap (B*(l))\n",
    "    B_star_l = c_lambda_l * L_g\n",
    "    \n",
    "    # Expected meters cycled per investment unit (B(g)), accounting for cost-efficiency\n",
    "    B_g = B_star_l / L_g if L_g > 0 else 0\n",
    "    \n",
    "    # Store the benefit metric for each gap\n",
    "    gap_closure_benefits[(source, target)] = B_g\n",
    "\n",
    "# Sort the gaps by their benefit metric in descending order\n",
    "sorted_gaps_by_benefit = sorted(gap_closure_benefits.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print the sorted gaps with their benefit metric\n",
    "for (source, target), benefit in sorted_gaps_by_benefit:\n",
    "    print(f\"Gap from {source} to {target}: Benefit Metric = {benefit}\")\n",
    "\n",
    "# Extract the benefit metrics from the sorted list\n",
    "benefits = [benefit for (source, target), benefit in sorted_gaps_by_benefit]\n",
    "\n",
    "# Create a rank for each gap based on its position in the sorted list\n",
    "ranks = range(1, len(benefits) + 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ranks, benefits, marker='o', linestyle='-', color='b')\n",
    "plt.title('Heterogeneity of Gap Closure Benefits')\n",
    "plt.xlabel('Gap Rank')\n",
    "plt.ylabel('Benefit Metric B(g)')\n",
    "plt.grid(True)\n",
    "file_path = os.path.join(city_folder_path, 'heter_gapclosure_benefits.png')\n",
    "plt.savefig(file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the declustering step I need to:\n",
    "\n",
    "1. Filter out the gaps with a benefit metric \\( B(g) \\) below a certain cutoff threshold \\( B(g)_{min} \\).\n",
    "2. Create a network from the remaining gaps.\n",
    "3. Decompose the network into disconnected components.\n",
    "4. For each disconnected component, while it is not empty, do the following:\n",
    "   - Compute all shortest paths between the nodes in the component.\n",
    "   - Calculate the benefit metric for each path.\n",
    "   - Find the path with the highest benefit metric and add it to the final gap list.\n",
    "   - Remove the path from the component.\n",
    "5. From the final gap list, remove the gaps with a benefit metric below the cutoff threshold \\( B(g)_{min} \\) again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDCP procedure - Declustering\n",
    "\n",
    "# Count the number of gaps before declustering\n",
    "num_gaps_before = len(filtered_gaps)\n",
    "print(f\"Number of gaps before declustering: {num_gaps_before}\")\n",
    "\n",
    "# Assuming B_g_min is the cut-off benefit metric value\n",
    "B_g_min = 200\n",
    "print(f\"Cut-off benefit metric (B_g_min): {B_g_min}\")\n",
    "\n",
    "# Step 1: Filter out gaps with B(g) higher than B_g_min\n",
    "gaps_above_threshold = {k: v for k, v in gap_closure_benefits.items() if v >= B_g_min}\n",
    "print(f\"Number of gaps above threshold: {len(gaps_above_threshold)}\")\n",
    "\n",
    "# Step 2: Create a network/graph from the remaining gaps\n",
    "G_network = nx.Graph()\n",
    "for (source, target), path in filtered_gaps.items():\n",
    "    if (source, target) in gaps_above_threshold:\n",
    "        # Add edges to the graph for each path segment\n",
    "        G_network.add_edges_from(zip(path[:-1], path[1:]))\n",
    "\n",
    "print(f\"Number of nodes in G_network: {G_network.number_of_nodes()}\")\n",
    "print(f\"Number of edges in G_network: {G_network.number_of_edges()}\")\n",
    "\n",
    "# Step 3: Decompose the network into disconnected components\n",
    "disconnected_components = list(nx.connected_components(G_network))\n",
    "print(f\"Number of disconnected components: {len(disconnected_components)}\")\n",
    "\n",
    "# List to hold the final non-overlapping gaps\n",
    "final_gap_list = []\n",
    "removed_paths = set()\n",
    "\n",
    "# Step 4: Process each component\n",
    "for component in disconnected_components:\n",
    "    comp_graph = G_network.subgraph(component).copy()\n",
    "\n",
    "    while comp_graph.number_of_edges() > 0:\n",
    "        # Compute all shortest paths in the component graph\n",
    "        all_paths = nx.shortest_path(comp_graph)\n",
    "\n",
    "        # Calculate benefit metric B(g) for each path\n",
    "        path_benefits = {}\n",
    "        for source, paths in all_paths.items():\n",
    "            for target, path in paths.items():\n",
    "                if source != target and (source, target) in filtered_gaps:\n",
    "                    B_star_l = sum(node_betweenness.get(node, 0) for node in path)\n",
    "                    L_g = sum(nx.get_edge_attributes(comp_graph, 'length').get(edge, 0) for edge in zip(path[:-1], path[1:]))\n",
    "                    B_g = B_star_l / L_g if L_g > 0 else 0\n",
    "                    path_benefits[(source, target)] = B_g\n",
    "\n",
    "        if path_benefits:\n",
    "            sorted_paths = sorted(path_benefits.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for p_max, _ in sorted_paths:\n",
    "                if p_max not in removed_paths:\n",
    "                    break\n",
    "            else:\n",
    "                print(\"No new valid paths with benefits found in component. Skipping...\")\n",
    "                break\n",
    "\n",
    "            final_gap_list.append(p_max)\n",
    "            removed_paths.add(p_max)\n",
    "\n",
    "            p_max_edges = list(zip(filtered_gaps[p_max][:-1], filtered_gaps[p_max][1:]))\n",
    "            comp_graph.remove_edges_from(p_max_edges)\n",
    "\n",
    "            print(f\"Removed path: {p_max}\")\n",
    "            print(f\"Graph state after removal: {len(comp_graph.nodes())} nodes, {len(comp_graph.edges())} edges\")\n",
    "        else:\n",
    "            print(\"No valid paths with benefits found in component. Skipping...\")\n",
    "            break\n",
    "\n",
    "# Step 5: Remove gaps with B(g) less than B_g_min from the final gap list\n",
    "final_gap_list = [gap for gap in final_gap_list if gap_closure_benefits.get(gap, 0) >= B_g_min]\n",
    "print(f\"Final gap list before final threshold check: {final_gap_list}\")\n",
    "\n",
    "final_gap_list_paths = [filtered_gaps[gap] for gap in final_gap_list]\n",
    "print(final_gap_list_paths[:5])\n",
    "print(f\"Number of gaps after declustering: {len(final_gap_list_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gap_list_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot declustered gaps\n",
    "import folium\n",
    "import random\n",
    "from shapely import wkt\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "all_lts_df = pd.read_csv(\"/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/Trento_all_lts.csv\")\n",
    "\n",
    "# Convert 'geometry' column from WKT strings to actual geometry objects\n",
    "all_lts_df['geometry'] = all_lts_df['geometry'].apply(wkt.loads)\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "all_lts = gpd.GeoDataFrame(all_lts_df, geometry='geometry')\n",
    "\n",
    "# Set the CRS for the GeoDataFrame\n",
    "all_lts.crs = \"EPSG:32632\"\n",
    "\n",
    "# Reproject to WGS84\n",
    "all_lts_projected = all_lts.to_crs(epsg=4326)\n",
    "\n",
    "# Calculate the mean of latitudes and longitudes\n",
    "mean_latitude = all_lts_projected.geometry.apply(lambda geom: geom.centroid.y).mean()\n",
    "mean_longitude = all_lts_projected.geometry.apply(lambda geom: geom.centroid.x).mean()\n",
    "\n",
    "# Create the folium map object\n",
    "m = folium.Map(location=[mean_latitude, mean_longitude], zoom_start=13)\n",
    "\n",
    "# Define styles for different road types\n",
    "highway_styles = {\n",
    "    'motorway': {'weight': 5, 'color': \"#a6a6a6\"},\n",
    "    'primary': {'weight': 4, 'color': \"#676767\"},\n",
    "    'secondary': {'weight': 3, 'color': \"#707070\"},\n",
    "    'tertiary': {'weight': 2, 'color': \"#bdbdbd\"},\n",
    "    'residential': {'weight': 1, 'color': \"#d5d5d5\"},\n",
    "    'default': {'weight': 1, 'color': \"rgba(0, 0, 0, 0)\"}\n",
    "}\n",
    "\n",
    "# Plot the roads by their type\n",
    "for u, v, data in G_lts.edges(data=True):\n",
    "    edge_type = data.get('highway', 'default')\n",
    "    style = highway_styles.get(edge_type, highway_styles['default'])\n",
    "    points = [\n",
    "        (G_lts.nodes[u]['y'], G_lts.nodes[u]['x']),\n",
    "        (G_lts.nodes[v]['y'], G_lts.nodes[v]['x'])\n",
    "    ]\n",
    "    folium.PolyLine(points, **style).add_to(m)\n",
    "\n",
    "# Assuming you have a basemaps dictionary like in the author's code\n",
    "for key in [\"OpenStreetMap\", \"CartoDB positron\", \"CartoDB dark_matter\"]:\n",
    "    folium.TileLayer(key).add_to(m)\n",
    "\n",
    "# Define the FeatureGroup for declustered gaps\n",
    "gaps_fg = folium.FeatureGroup(\"Declustered gaps\", show=True)\n",
    "\n",
    "# Assuming 'filtered_gaps' is a dictionary with gap identifiers as keys and lists of node tuples as values\n",
    "# and 'G_lts' is your graph object from which we can get node coordinates\n",
    "for gap in final_gap_list_paths:\n",
    "    # Extract the coordinates for each gap's path\n",
    "    coords = [(G_lts.nodes[node]['y'], G_lts.nodes[node]['x']) for node in gap]\n",
    "    \n",
    "    # Create a PolyLine for each gap\n",
    "    folium.PolyLine(\n",
    "        locations=coords,\n",
    "        weight=6,\n",
    "        color=\"black\"  # black border\n",
    "    ).add_to(gaps_fg)\n",
    "    \n",
    "    # Create a second PolyLine for a colored line within the black border\n",
    "    folium.PolyLine(\n",
    "        locations=coords,\n",
    "        weight=4,\n",
    "        color=random.choice([\"#33FFDA\", \"#0AB023\", \"#B00A60\", \"#0A3CB0\"])  # randomly colored gaps\n",
    "    ).add_to(gaps_fg)\n",
    "\n",
    "# Add the gaps FeatureGroup to the map\n",
    "gaps_fg.add_to(m)\n",
    "\n",
    "# Now add a FeatureGroup for gap numbers if you want to label them\n",
    "my_fg_nr = folium.FeatureGroup(\"Gap numbers\", show=True)\n",
    "\n",
    "# Add pop-ups with gap numbers\n",
    "for i, gap in enumerate(final_gap_list_paths):\n",
    "#for i, gap in enumerate(filtered_gaps):\n",
    "    start_node = gap[0]\n",
    "    folium.Marker(\n",
    "        location=(G_lts.nodes[start_node]['y'], G_lts.nodes[start_node]['x']),\n",
    "        popup=\"Gap \" + str(i)\n",
    "    ).add_to(my_fg_nr)\n",
    "\n",
    "# Add the gap numbers FeatureGroup to the map\n",
    "my_fg_nr.add_to(m)\n",
    "\n",
    "# Add Layer Control and save/display the map\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "file_path = os.path.join(city_folder_path, 'gaps_declustered_plot.html')\n",
    "\n",
    "# Assuming 'accident_map' is a Folium Map object\n",
    "m.save(file_path)\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/Trento_lts.graphml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define namespaces to search for elements within the GraphML file\n",
    "ns = {'graphml': 'http://graphml.graphdrawing.org/xmlns'}\n",
    "\n",
    "# Find all nodes and edges within the GraphML file\n",
    "edges = root.findall('graphml:graph/graphml:edge', namespaces=ns)\n",
    "\n",
    "edge_names = {}\n",
    "\n",
    "for edge in edges:\n",
    "    edge_id = f\"{edge.get('source')}-{edge.get('target')}\"\n",
    "    name_data = edge.find(\"graphml:data[@key='d9']\", namespaces=ns)\n",
    "    if name_data is not None:\n",
    "        # Check and print what is actually being read\n",
    "        # print(f\"Edge ID: {edge_id}, Name Data: {name_data.text}\")\n",
    "        names = name_data.text.strip('[]').replace(\"'\", \"\").split(', ')\n",
    "        edge_names[edge_id] = names\n",
    "\n",
    "# Debugging information to check the dictionary\n",
    "# print(\"Edge Names Dictionary:\", edge_names)\n",
    "\n",
    "# Define the function to get edge names from the path\n",
    "def get_edge_names_from_path(path, edge_names):\n",
    "    edge_name_list = []\n",
    "    for i in range(len(path) - 1):\n",
    "        edge_id = f\"{path[i]}-{path[i+1]}\"  \n",
    "        if edge_id in edge_names:\n",
    "            for name in edge_names[edge_id]:\n",
    "                if name not in edge_name_list:\n",
    "                    edge_name_list.append(name)\n",
    "        else:\n",
    "            print(f\"Edge ID not found in dictionary: {edge_id}\")\n",
    "    return edge_name_list\n",
    "\n",
    "\n",
    "# Get edge names for each gap and debug\n",
    "for gap_path in final_gap_list_paths:\n",
    "    names = get_edge_names_from_path(gap_path, edge_names)\n",
    "    # print(\"Edge names for gap:\", names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDCP procedure - Classification\n",
    "from pprint import pprint\n",
    "\n",
    "# Define the classify_gaps function\n",
    "def classify_gaps(gaps, edge_names, graph):\n",
    "    gap_info = {}\n",
    "\n",
    "    for gap in gaps:\n",
    "        # Retrieve the unique names of edges for this gap\n",
    "        unique_edge_names = get_edge_names_from_path(gap, edge_names)\n",
    "        \n",
    "        # Initialize the gap dictionary\n",
    "        gap_dict = {\n",
    "            'intersections': [],  # this will be filled with intersection data\n",
    "            'bridge': any('ponte' in name.lower() for name in unique_edge_names),  # check if any edge name contains 'ponte'\n",
    "            'type': 'bridge' if any('ponte' in name.lower() for name in unique_edge_names) else 'street',\n",
    "            'edges_name': unique_edge_names\n",
    "        }\n",
    "\n",
    "        # Add intersection data if it's not a bridge\n",
    "        if not gap_dict['bridge']:\n",
    "            for i in range(len(gap) - 1):\n",
    "                node_data = graph.nodes[gap[i+1]]\n",
    "                intersection_info = {\n",
    "                    'node': gap[i+1],\n",
    "                    'coordinates': (node_data.get('x'), node_data.get('y'))\n",
    "                }\n",
    "                gap_dict['intersections'].append(intersection_info)\n",
    "        \n",
    "        # Assign the gap_dict to the gap key in gap_info\n",
    "        gap_info[tuple(gap)] = gap_dict\n",
    "\n",
    "    return gap_info\n",
    "\n",
    "# Call the classify_gaps function and store the result\n",
    "classified_gaps = classify_gaps(final_gap_list_paths, edge_names, G_lts)\n",
    "\n",
    "# Print the classified gaps in a readable format\n",
    "#pprint(classified_gaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final gaps plot:\n",
    "\n",
    "gap_type_colors = {\n",
    "    'street': '#ff7800',\n",
    "    'bridge': '#0A3CB0',\n",
    "}\n",
    "\n",
    "# Add a legend to the map\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; bottom: 50px; left: 50px; width: 150px; height: 100px; \n",
    "background-color: white; border:2px solid grey; z-index:9999; font-size:14px;\">\n",
    "&nbsp; Legend <br>\n",
    "&nbsp; Street &nbsp; <i style=\"background-color:#ff7800;\">&nbsp;&nbsp;&nbsp;&nbsp;</i><br>\n",
    "&nbsp; Bridge &nbsp; <i style=\"background-color:#0A3CB0;\">&nbsp;&nbsp;&nbsp;&nbsp;</i><br>\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "for gap_id, gap_data in classified_gaps.items():\n",
    "    coords = [(G_lts.nodes[node]['y'], G_lts.nodes[node]['x']) for node in gap_id]\n",
    "\n",
    "    folium.PolyLine(\n",
    "        locations=coords,\n",
    "        weight=6,\n",
    "        color=gap_type_colors.get(gap_data['type'], '#ffffff')  # default color if type not found\n",
    "    ).add_to(gaps_fg)\n",
    "\n",
    "    # Assuming you want to label the gaps with their names\n",
    "    edge_names = ' - '.join(gap_data['edges_name'])\n",
    "    folium.Marker(\n",
    "        location=coords[0],\n",
    "        popup=f\"Gap {edge_names}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "file_path = os.path.join(city_folder_path, 'gaps_classified_plot.html')\n",
    "\n",
    "# Assuming 'accident_map' is a Folium Map object\n",
    "m.save(file_path)\n",
    "#display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
