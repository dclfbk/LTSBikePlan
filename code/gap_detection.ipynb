{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these is edges data:    key  lanes                                    name       highway  maxspeed  \\\n",
      "0    0    NaN          ['Largo Duomo', 'Piazza Roma']     secondary       NaN   \n",
      "1    0    NaN          ['Largo Duomo', 'Piazza Roma']     secondary       NaN   \n",
      "2    0    NaN  ['Via Marziano Ciotti', 'Piazza Roma']     secondary       NaN   \n",
      "3    0    NaN                         ['Piazza Roma']  unclassified       NaN   \n",
      "4    0    NaN                         ['Piazza Roma']  unclassified       NaN   \n",
      "\n",
      "                                            geometry  length rule  lts  group  \\\n",
      "0  LINESTRING (782693.903763619 5118386.029298064...  50.625  m12    4      1   \n",
      "1  LINESTRING (782685.2558167536 5118435.77659598...  50.625  m12    4      1   \n",
      "2  LINESTRING (782695.9299623996 5118354.87035418...  31.325  m12    4      1   \n",
      "3  LINESTRING (782713.8450469453 5118390.13402393...  20.291  m10    3      1   \n",
      "4  LINESTRING (782693.903763619 5118386.029298064...  20.291  m10    3      1   \n",
      "\n",
      "   ...  slope_class lanes_assumed  maxspeed_assumed  \\\n",
      "0  ...    0-3: flat           2.0              90.0   \n",
      "1  ...    0-3: flat           2.0              90.0   \n",
      "2  ...    0-3: flat           2.0              90.0   \n",
      "3  ...    0-3: flat           2.0              50.0   \n",
      "4  ...    0-3: flat           2.0              50.0   \n",
      "\n",
      "                                             message  \\\n",
      "0  Setting LTS to 4 because maxspeed is greater t...   \n",
      "1  Setting LTS to 4 because maxspeed is greater t...   \n",
      "2  Setting LTS to 4 because maxspeed is greater t...   \n",
      "3  Setting LTS to 3 because maxspeed is up to 50 ...   \n",
      "4  Setting LTS to 3 because maxspeed is up to 50 ...   \n",
      "\n",
      "                                       short_message                  edge_id  \\\n",
      "0                   mixed traffic, speed $>$ 50 km/h   [275047641, 912303265]   \n",
      "1                   mixed traffic, speed $>$ 50 km/h   [275047641, 912303265]   \n",
      "2                   mixed traffic, speed $>$ 50 km/h  [275047641, 6532857567]   \n",
      "3  mixed traffic, speed $\\leq$ 50 km/h, highway $...   [275047641, 912303407]   \n",
      "4  mixed traffic, speed $\\leq$ 50 km/h, highway $...   [275047641, 912303407]   \n",
      "\n",
      "  type_stress                                          attr_dict       orig  \\\n",
      "0        high  {'length': 50.625, 'category_edge': 'high', 'e...  275047641   \n",
      "1        high  {'length': 50.625, 'category_edge': 'high', 'e...  275047641   \n",
      "2        high  {'length': 31.325, 'category_edge': 'high', 'e...  275047641   \n",
      "3        high  {'length': 20.291, 'category_edge': 'high', 'e...  275047641   \n",
      "4        high  {'length': 20.291, 'category_edge': 'high', 'e...  275047641   \n",
      "\n",
      "         dest  \n",
      "0   912303265  \n",
      "1   912303265  \n",
      "2  6532857567  \n",
      "3   912303407  \n",
      "4   912303407  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import igraph as ig\n",
    "from ast import literal_eval\n",
    "import pickle as pkl\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Useful functions\n",
    "\n",
    "def make_attr_dict(*args, **kwargs): \n",
    "    \n",
    "    argCount = len(kwargs)\n",
    "    \n",
    "    if argCount > 0:\n",
    "        attributes = {}\n",
    "        for kwarg in kwargs:\n",
    "            attributes[kwarg] = kwargs.get(kwarg, None)\n",
    "        return attributes\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Load data\n",
    "nodes_path = \"../data/Montereale_Valcellina_gdf_nodes.csv\"\n",
    "edges_path = \"../data/Montereale_Valcellina_all_lts.csv\"\n",
    "nodes_data = pd.read_csv(nodes_path)\n",
    "nodes_data = nodes_data[nodes_data['lts'].isin([1, 2, 3, 4])].copy()\n",
    "nodes_data['lts'] = nodes_data['lts'].astype(int)\n",
    "edges_data = pd.read_csv(edges_path)\n",
    "\n",
    "edges_data = edges_data[edges_data['lts'].isin([1, 2, 3, 4])].copy()\n",
    "edges_data['lts'] = edges_data['lts'].astype(int)\n",
    "\n",
    "# Adding info on the type\n",
    "nodes_data['type_stress'] = np.where(nodes_data['lts'].isin([1, 2]), 'low', \n",
    "                                     np.where(nodes_data['lts'].isin([3, 4]), 'high', np.nan))\n",
    "nodes_data = nodes_data.sort_values(by = \"osmid\").reset_index(drop = True)\n",
    "nodes_data[\"attr_dict\"] = nodes_data.apply(lambda x: make_attr_dict(category_node = x.type_stress, coord = x.geometry), axis = 1)\n",
    "\n",
    "# Add edge ids (strings with \"id1, id2\" sorted (id1 <id2))\n",
    "edges_data[\"edge_id\"] = edges_data.apply(lambda x: str(sorted([x[\"u\"], x[\"v\"]])), axis = 1)\n",
    "\n",
    "# Adding info on the type\n",
    "edges_data['type_stress'] = np.where(edges_data['lts'].isin([1, 2]), 'low', \n",
    "                                     np.where(edges_data['lts'].isin([3, 4]), 'high', np.nan))\n",
    "\n",
    "# Finding duplicates by [\"u\",\"v\",\"osmid\", \"oneway\", \"edge_id\", \"length\", \"type_stress\"]\n",
    "# Simplifying network into undirected \n",
    "# Removing all parallel edges\n",
    "\n",
    "edges_data = edges_data.drop_duplicates(subset = [\"u\", \"v\", \"osmid\", \"length\", \"edge_id\", \"type_stress\"],\n",
    "                  keep = \"first\",\n",
    "                  inplace = False,\n",
    "                  ignore_index = True).copy()\n",
    "\n",
    "# Add attribute dictionary (for nx)\n",
    "edges_data[\"attr_dict\"] = edges_data.apply(lambda x: make_attr_dict(length = x.length, \n",
    "                                                    category_edge = x.type_stress,\n",
    "                                                    edge_id = x.edge_id,\n",
    "                                                    coord = x.geometry,\n",
    "                                                    intnodes = []), # intnodes attribute: for storing simplification info on interstitial nodes \n",
    "                             axis = 1)\n",
    "\n",
    "# sort by \"left\" node (id1 < id2 - to control order of tuple keys in nx)\n",
    "edges_data[\"order\"] = edges_data.apply(lambda x: np.min([x[\"u\"], x[\"v\"]]), axis = 1)\n",
    "edges_data = edges_data.sort_values(by = \"order\").reset_index(drop = True)\n",
    "edges_data[\"orig\"] = edges_data.apply(lambda x: np.min([x[\"u\"], x[\"v\"]]), axis = 1)\n",
    "edges_data[\"dest\"] = edges_data.apply(lambda x: np.max([x[\"u\"], x[\"v\"]]), axis = 1)\n",
    "edges_data = edges_data.drop(columns = [\"order\", \"u\", \"v\", \"osmid\"]) # instead of \"u\" and \"v\",\n",
    "# we will use \"origin\" and \"destination\" where osmid(origin) < osmid (destination)!\n",
    "print(\"these is edges data:\", edges_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few nodes and their attributes:\n",
      "275047641 {'category_node': 'high', 'coord': 'POINT (12.6615432 46.1603739)'}\n",
      "275047646 {'category_node': 'high', 'coord': 'POINT (12.6603584 46.1576454)'}\n",
      "275047789 {'category_node': 'high', 'coord': 'POINT (12.6516924 46.1014144)'}\n",
      "275047807 {'category_node': 'high', 'coord': 'POINT (12.6684513 46.1461234)'}\n",
      "275048618 {'category_node': 'high', 'coord': 'POINT (12.6611966 46.1630372)'}\n",
      "\n",
      "First few edges and their attributes:\n",
      "(275047641, 912303265, {'length': 50.625, 'category_edge': 'high', 'edge_id': '[275047641, 912303265]', 'coord': 'LINESTRING (782685.2558167536 5118435.776595989, 782686.9408203791 5118417.20532012, 782691.20776897 5118394.488988528, 782693.903763619 5118386.029298064)', 'intnodes': []})\n",
      "(275047641, 6532857567, {'length': 31.325, 'category_edge': 'high', 'edge_id': '[275047641, 6532857567]', 'coord': 'LINESTRING (782693.903763619 5118386.029298064, 782695.5478483913 5118378.066608992, 782695.7932620606 5118371.408813569, 782695.8524641837 5118359.231211402, 782695.9299623996 5118354.870354182)', 'intnodes': []})\n",
      "(275047641, 912303407, {'length': 20.291, 'category_edge': 'high', 'edge_id': '[275047641, 912303407]', 'coord': 'LINESTRING (782693.903763619 5118386.029298064, 782713.8450469453 5118390.134023931)', 'intnodes': []})\n",
      "(275047646, 3493141395, {'length': 41.29, 'category_edge': 'high', 'edge_id': '[275047646, 3493141395]', 'coord': 'LINESTRING (782616.4220632755 5118078.669204095, 782622.550168131 5118098.447142744, 782626.2858500159 5118109.541716436, 782629.1305996091 5118117.978753634)', 'intnodes': []})\n",
      "(275047646, 1812883495, {'length': 24.18, 'category_edge': 'high', 'edge_id': '[275047646, 1812883495]', 'coord': 'LINESTRING (782616.4220632755 5118078.669204095, 782602.1364314347 5118059.116123357)', 'intnodes': []})\n",
      "number of disconnected components on mnw: 3\n",
      "size of lcc: 901\n"
     ]
    }
   ],
   "source": [
    "# CREATE NX OBJECTS\n",
    "\n",
    "# make multinetwork containing ALL edges\n",
    "mnw = nx.Graph()\n",
    "mnw.add_nodes_from(nodes_data.loc[:,[\"osmid\", \"attr_dict\"]].itertuples(index = False))\n",
    "mnw.add_edges_from(edges_data.loc[:,[\"orig\", \"dest\", \"attr_dict\"]].itertuples(index = False))\n",
    "\n",
    "# save to pickle (\"original\" nw = non-simplified, with disconnected components)\n",
    "nx.write_gpickle(mnw, \"../data/mnw.gpickle\")\n",
    "\n",
    "# Sample Nodes and Edges\n",
    "print(\"\\nFirst few nodes and their attributes:\")\n",
    "for node, data in list(mnw.nodes(data=True))[:5]:\n",
    "    print(node, data)\n",
    "\n",
    "print(\"\\nFirst few edges and their attributes:\")\n",
    "for edge in list(mnw.edges(data=True))[:5]:\n",
    "    print(edge)\n",
    "\n",
    "# KEEP ONLY LARGEST CONNECTED COMPONENT\n",
    "\n",
    "# make list of connected components\n",
    "cd_nodeset = []\n",
    "\n",
    "for comp in nx.connected_components(mnw):\n",
    "    \n",
    "    cd_nodeset = cd_nodeset + [comp]\n",
    "    \n",
    "n = len(cd_nodeset)\n",
    "    \n",
    "print(\"number of disconnected components on mnw: \" + str(n))\n",
    "\n",
    "cd_size = [None]*n\n",
    "cd_network = [None]*n\n",
    "cd_coord_dict = [None]*n\n",
    "cd_coord_list = [None]*n\n",
    "cd_type_stress = [None]*n\n",
    "\n",
    "for i in range(n):\n",
    "    cd_size[i] = len(cd_nodeset[i])\n",
    "    cd_network[i] = nx.subgraph(mnw, cd_nodeset[i])\n",
    "    cd_coord_dict[i] = nx.get_edge_attributes(cd_network[i], \"coord\")\n",
    "    cd_coord_list[i] = [cd_coord_dict[i][key] for key in cd_coord_dict[i].keys()]\n",
    "    cd_type_stress[i] = nx.get_edge_attributes(cd_network[i], \"category_edge\")\n",
    "\n",
    "# make df with info on connected components\n",
    "comps = pd.DataFrame({\n",
    "    'nodeset': cd_nodeset, \n",
    "    'size': cd_size,\n",
    "    'network': cd_network,\n",
    "    'coord': cd_coord_list,\n",
    "    'type_stress': cd_type_stress})\n",
    "\n",
    "del(cd_nodeset, cd_size, cd_network, cd_coord_list, cd_type_stress, cd_coord_dict)\n",
    "\n",
    "# lcc is the size of the largest connected component\n",
    "lcc = np.max(comps[\"size\"])\n",
    "\n",
    "print(\"size of lcc: \" + str(lcc))\n",
    "\n",
    "comps = comps.sort_values(by = \"size\", ascending = False).reset_index(drop = True)\n",
    "\n",
    "# DEFINE MNWL as largest connected component\n",
    "mnwl_nodes = comps[\"nodeset\"][0]\n",
    "mnwl_edges = edges_data.loc[edges_data.apply(lambda x: x.orig in mnwl_nodes, axis = 1),:].copy().reset_index(drop = True)\n",
    "mnwl = nx.subgraph(mnw, mnwl_nodes)\n",
    "\n",
    "# save as pickle (\"original\" nw = non-simplified, but only LCC)\n",
    "nx.write_gpickle(mnwl, \"../data/mnwl.gpickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1, Mon Oct 30 23:22:15 2023\n",
      "Run 2, Mon Oct 30 23:22:15 2023\n",
      "Run 3, Mon Oct 30 23:22:15 2023\n",
      "Run 4, Mon Oct 30 23:22:15 2023\n",
      "Done\n",
      "First few nodes: [275047641, 275047646, 275047789, 275047807, 275048618]\n",
      "First few edges: [(275047641, 912303265, {'length': 50.625, 'category_edge': 'high', 'edge_id': '[275047641, 912303265]', 'coord': 'LINESTRING (782685.2558167536 5118435.776595989, 782686.9408203791 5118417.20532012, 782691.20776897 5118394.488988528, 782693.903763619 5118386.029298064)', 'intnodes': []}), (275047641, 6532857567, {'length': 31.325, 'category_edge': 'high', 'edge_id': '[275047641, 6532857567]', 'coord': 'LINESTRING (782693.903763619 5118386.029298064, 782695.5478483913 5118378.066608992, 782695.7932620606 5118371.408813569, 782695.8524641837 5118359.231211402, 782695.9299623996 5118354.870354182)', 'intnodes': []}), (275047641, 912285611, {'length': 90.04799999999999, 'category_edge': 'high', 'intnodes': [912304324, 912303407], 'edge_id': '[275047641, 912285611]', 'coord': 'LINESTRING (782693.903763619 5118386.029298064, 782713.8450469453 5118390.134023931)LINESTRING (782726.2064845853 5118393.020471946, 782780.1896536882 5118412.19111588)LINESTRING (782713.8450469453 5118390.134023931, 782726.2064845853 5118393.020471946)'}), (275047646, 3493141395, {'length': 41.29, 'category_edge': 'high', 'edge_id': '[275047646, 3493141395]', 'coord': 'LINESTRING (782616.4220632755 5118078.669204095, 782622.550168131 5118098.447142744, 782626.2858500159 5118109.541716436, 782629.1305996091 5118117.978753634)', 'intnodes': []}), (275047646, 1812883495, {'length': 24.18, 'category_edge': 'high', 'edge_id': '[275047646, 1812883495]', 'coord': 'LINESTRING (782616.4220632755 5118078.669204095, 782602.1364314347 5118059.116123357)', 'intnodes': []})]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "# make a copy of mnwl - H will be simplified and manipulated throughout while loop\n",
    "H = mnwl.copy()\n",
    "\n",
    "# set parameters for the while loop\n",
    "simplify_further = True\n",
    "run = 0\n",
    "\n",
    "# make dictionary of edge attributes of mnwl\n",
    "mnwl_typedict = nx.get_edge_attributes(mnwl, \"category_edge\")\n",
    "\n",
    "# loop runs while there are interstitial nodes on the nw\n",
    "while simplify_further:\n",
    "    \n",
    "    run += 1\n",
    "    print(\"Run \" + str(run) + \", \" + time.ctime())\n",
    "    \n",
    "    # get all nodes from nw\n",
    "    points_all_list = sorted(list(H.nodes))\n",
    "\n",
    "    # get all node degrees\n",
    "    degrees_all_list = [None]*len(points_all_list)\n",
    "    for i in range(len(points_all_list)):\n",
    "        degrees_all_list[i] = H.degree(points_all_list[i])\n",
    "\n",
    "    # make df with node + degree info + remove (T/F) + types (of incident edges)\n",
    "    pointsall = pd.DataFrame({\n",
    "        \"osmid\": points_all_list, \n",
    "        \"d\": degrees_all_list, \n",
    "        \"remove\": None, \n",
    "        \"types\": None})\n",
    "    \n",
    "    # get edge attributes (of CURRENT nw) as dict\n",
    "    catdict = nx.get_edge_attributes(H, \"category_edge\")\n",
    "    # get edge type information (car/bike/multi) from attribute dictionary\n",
    "    pointsall[\"types\"] = pointsall.apply(lambda x: \n",
    "                                     [ catdict[tuple(sorted(edge))] for edge in H.edges(x.osmid) if tuple(sorted(edge)) in catdict], \n",
    "                                     axis = 1)\n",
    "\n",
    "\n",
    "    # split df in \"endpoints\" and d2 nodes\n",
    "    pointsend = pointsall[pointsall[\"d\"]!=2].copy().reset_index(drop = True)\n",
    "    pointsd2 = pointsall[pointsall[\"d\"]==2].copy().reset_index(drop = True)\n",
    "\n",
    "    # non-d2 nodes: all of them are remove=False (to keep)\n",
    "    pointsend[\"remove\"] = False\n",
    "    # d2 nodes: the ones that have same 2 edge types incident are remove=True\n",
    "    pointsd2[\"remove\"] = pointsd2.apply(lambda x: x.types[0] == x.types[1] if len(x.types) > 1 else False, axis=1)\n",
    "\n",
    "    # final result: 2 dfs - nodes_final and nodes_interstitial\n",
    "\n",
    "    # nodes_final = nodes to keep (either they have d!=2 or they have d==2 but 2 different edge types)\n",
    "    nodes_final = pd.concat([pointsend, pointsd2[pointsd2[\"remove\"]==False].copy()]).reset_index(drop = True)\n",
    "\n",
    "    # nodes_interstitial = nodes to remove (d2 nodes with same 2 edge types incident)\n",
    "    nodes_interstitial = pointsd2[pointsd2[\"remove\"]==True].copy().reset_index(drop = True)\n",
    "    nodes_interstitial[\"types\"] = nodes_interstitial.apply(lambda x: x.types[0], axis = 1) # remove second-edge info (is same as first)\n",
    "\n",
    "    del(pointsall, catdict, degrees_all_list, points_all_list, pointsend, pointsd2)\n",
    "\n",
    "    # save info about endpoint/interstitial to node attributes on mnwl\n",
    "    for i in range(len(nodes_interstitial)):\n",
    "        H.nodes[nodes_interstitial.loc[i, \"osmid\"]][\"category_point\"] = \"int\"\n",
    "    for i in range(len(nodes_final)):\n",
    "        H.nodes[nodes_final.loc[i, \"osmid\"]][\"category_point\"] = \"end\"\n",
    "\n",
    "    # make df with interstitial edges\n",
    "    eint = nodes_interstitial.copy() \n",
    "    eint[\"orig\"] = eint.apply(lambda x: sorted([n for n in H.neighbors(x.osmid)])[0], axis = 1)\n",
    "    eint[\"dest\"] = eint.apply(lambda x: sorted([n for n in H.neighbors(x.osmid)])[1], axis = 1)\n",
    "\n",
    "    # add info on edge lengths\n",
    "    lendict = nx.get_edge_attributes(H, \"length\")\n",
    "    eint[\"length_new\"] = eint.apply(lambda x: \n",
    "                                    np.sum(\n",
    "                                        [lendict[tuple(sorted(edge))] for edge in H.edges(x.osmid)]\n",
    "                                    ), \n",
    "                                    axis = 1)\n",
    "\n",
    "    stack = list(np.unique(eint[\"osmid\"]))\n",
    "    \n",
    "    Hprior = H.copy() # make a copy of the nw in each simplification step\n",
    "    # to use for checking for neighbours for removing from stack\n",
    "    \n",
    "    # interstitial nodes dictionary - to keep track of nodes that are removed by \"while stack\"\n",
    "    intnodesdict = nx.get_edge_attributes(H, \"intnodes\")\n",
    "    # edge coordinate dictionary - to merge linestrings of aggregated edges\n",
    "    edgecoorddict = nx.get_edge_attributes(H, \"coord\")\n",
    "    \n",
    "    while stack:\n",
    "\n",
    "        mynode = stack.pop()\n",
    "        \n",
    "        for n in nx.neighbors(Hprior, mynode): # remove neighbors from ORIGINAL nw\n",
    "            if n in stack:\n",
    "                stack.remove(n)\n",
    "                #print(\"removed \"+ str(n))\n",
    "                \n",
    "        # u and v are the neighbors of \"mynode\"\n",
    "        u = eint.loc[eint[\"osmid\"]==mynode][\"orig\"].values[0]\n",
    "        v = eint.loc[eint[\"osmid\"]==mynode][\"dest\"].values[0]\n",
    "        \n",
    "        # counter (to break out of loop if it is not increased)\n",
    "        nodes_removed = 0\n",
    "        \n",
    "        if (u,v) not in H.edges: # only if neighbors are not neighbors themselves - \n",
    "            # to avoid roundabouts from disappearing\n",
    "            \n",
    "            # get info on interstitional nodes (for deriving edge coordinates later on)\n",
    "            myintnodes = [intnodesdict[tuple(sorted(edge))] for edge in H.edges(mynode)]\n",
    "            myintnodes.append([mynode])\n",
    "            myintnodes = [x for x in list(itertools.chain.from_iterable(myintnodes)) if x]\n",
    "            \n",
    "            H.add_edge(u_of_edge = u,\n",
    "                        v_of_edge = v,\n",
    "                        length = eint.loc[eint[\"osmid\"]==mynode][\"length_new\"].values[0],\n",
    "                        category_edge = eint.loc[eint[\"osmid\"]==mynode][\"types\"].values[0],\n",
    "                        intnodes = myintnodes,\n",
    "                        edge_id = str(sorted([u, v])),\n",
    "                        coord=edgecoorddict.get(tuple(sorted([u, mynode])), []) + edgecoorddict.get(tuple(sorted([v, mynode])), []))\n",
    "\n",
    "            H.remove_node(mynode)\n",
    "            nodes_removed += 1\n",
    "    \n",
    "    if nodes_removed == 0:\n",
    "        \n",
    "        simplify_further = False # to break out of loop\n",
    "                \n",
    "        # save simplified network to H gpickle\n",
    "        nx.write_gpickle(H, \"../data/H.gpickle\") \n",
    "        \n",
    "        print(\"Done\")\n",
    "\n",
    "print(\"First few nodes:\", list(H.nodes())[:5])\n",
    "print(\"First few edges:\", list(H.edges(data=True))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make \"bikeable\" network from H (excluding high stress edges)\n",
    "bikeable_nodes = [node for node in H.nodes if \"category_node\" in H.nodes[node] and H.nodes[node][\"category_node\"] != \"high\"]\n",
    "H_lowlts_induced = H.subgraph(bikeable_nodes).copy() \n",
    "\n",
    "# induced subgraph - still contains the highstress edges that lie between multi nodes; - exclude them:\n",
    "banw = H_lowlts_induced.copy()\n",
    "banw.remove_edges_from([edge for edge in banw.edges if banw.edges[edge][\"category_edge\"]==\"high\"])\n",
    "\n",
    "nx.write_gpickle(banw, \"../data/B.gpickle\") \n",
    "\n",
    "# conversion to igraph\n",
    "h = ig.Graph.from_networkx(H)\n",
    "h.write_pickle(\"../data/h.pickle\")\n",
    "b = ig.Graph.from_networkx(banw)\n",
    "b.write_pickle(\"../data/b.pickle\")\n",
    "\n",
    "# eids: \"conversion table\" for edge ids from igraph to nx \n",
    "eids_nx = [tuple(sorted(literal_eval(h.es(i)[\"edge_id\"][0]))) for i in range(len(h.es))]\n",
    "eids_ig = [i for i in range(len(h.es))]\n",
    "eids_conv = pd.DataFrame({\"nx\": eids_nx, \"ig\": eids_ig})\n",
    "\n",
    "# nids: \"conversion table\" for node ids from igraph to nx\n",
    "nids_nx = [h.vs(i)[\"_nx_name\"][0] for i in range(len(h.vs))]\n",
    "nids_ig = [i for i in range(len(h.vs))]\n",
    "nids_conv = pd.DataFrame({\"nx\": nids_nx, \"ig\": nids_ig})\n",
    "\n",
    "eids_conv.to_pickle(\"../data/eids_conv.pickle\")\n",
    "nids_conv.to_pickle(\"../data/nids_conv.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   edge_ig                 edge_nx   length    ebc_inf  ebc_lambda\n",
      "0        0   (33344145, 245980310)  106.472   734114.0      9521.0\n",
      "1        1  (33344145, 3325048776)  127.559   733786.0      9833.0\n",
      "2        2   (33344145, 245980471)  211.667     2293.0       974.0\n",
      "3        3  (33344145, 2925389440)  154.501     2329.0      1076.0\n",
      "4        4  (82550591, 8477370231)   19.042  1198831.0     25497.0\n"
     ]
    }
   ],
   "source": [
    "# extract edge and node attributes as dictionaries\n",
    "\n",
    "tnd = nx.get_node_attributes(H, \"category_node\") # type of nodes dictionary tnd\n",
    "ted = nx.get_edge_attributes(H, \"category_edge\") # type of edges dictionary tnd\n",
    "led = nx.get_edge_attributes(H, \"length\") # length of edges dictionary led\n",
    "cnd = nx.get_node_attributes(H, \"coord\") # coordinates of nodes dictionary cnd\n",
    "ced = nx.get_edge_attributes(H, \"coord\") # coordinates of edges dictionary ced\n",
    "\n",
    "# make data frame of ebc with:\n",
    "ebc = pd.DataFrame({\"edge_ig\": [e.index for e in h.es]}) # igraph edge ID\n",
    "ebc[\"edge_nx\"] = ebc.apply(lambda x: tuple(literal_eval(h.es[x.edge_ig][\"edge_id\"])), axis = 1) # nx edge ID\n",
    "ebc[\"length\"] = ebc.apply(lambda x: h.es[x.edge_ig][\"length\"], axis = 1) # length in meters\n",
    "\n",
    "# compute ebcs:\n",
    "ebc[\"ebc_inf\"] = h.edge_betweenness(directed = False, cutoff = None, weights = \"length\") # \"standard\" ebc\n",
    "ebc[\"ebc_lambda\"] = h.edge_betweenness(directed = False, cutoff = 2500, weights = \"length\") # ebc only including *paths* below 2500m\n",
    "print(ebc.head())\n",
    "\n",
    "ebc.to_pickle(\"../data/ebc.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079958 gaps found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb Cell 6\u001b[0m line \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m mygaps\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39menr\u001b[39m\u001b[39m\"\u001b[39m, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m# add coordinates for  plotting\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m mygaps[\u001b[39m\"\u001b[39m\u001b[39mgapcoord\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mygaps\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: get_path_coords(x\u001b[39m.\u001b[39;49mpath_nx, ced), axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:8848\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8837\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8839\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   8840\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   8841\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8846\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   8847\u001b[0m )\n\u001b[0;32m-> 8848\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:733\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    731\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:857\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 857\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    859\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    871\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    872\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    874\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    875\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    876\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    877\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb Cell 6\u001b[0m line \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m mygaps\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39menr\u001b[39m\u001b[39m\"\u001b[39m, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m# add coordinates for  plotting\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m mygaps[\u001b[39m\"\u001b[39m\u001b[39mgapcoord\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mygaps\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: get_path_coords(x\u001b[39m.\u001b[39;49mpath_nx, ced), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb Cell 6\u001b[0m line \u001b[0;36mget_path_coords\u001b[0;34m(my_path, my_coorddict)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m sorted_edge_id \u001b[39min\u001b[39;00m my_coorddict:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     linestring \u001b[39m=\u001b[39m my_coorddict[sorted_edge_id]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     edge_coords \u001b[39m=\u001b[39m extract_coords_from_linestring(linestring)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     pathcoords\u001b[39m.\u001b[39mappend(edge_coords)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb Cell 6\u001b[0m line \u001b[0;36mextract_coords_from_linestring\u001b[0;34m(linestring)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_coords_from_linestring\u001b[39m(linestring):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Extract coordinates using regex\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     matches \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+) (\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+)\u001b[39m\u001b[39m'\u001b[39m, linestring)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(\u001b[39mfloat\u001b[39m(y), \u001b[39mfloat\u001b[39m(x)) \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m matches]\n",
      "\u001b[1;32m/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb Cell 6\u001b[0m line \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_coords_from_linestring\u001b[39m(linestring):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Extract coordinates using regex\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     matches \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+) (\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+)\u001b[39m\u001b[39m'\u001b[39m, linestring)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/Tesi/LTSBikePlan/code/gap_detection.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(\u001b[39mfloat\u001b[39;49m(y), \u001b[39mfloat\u001b[39m(x)) \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m matches]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Identify and Prioritize\n",
    "import math\n",
    "\n",
    "# Custom Functions\n",
    "# computes pathlength by nx - handling error message if nodes are not connected/not part of the network\n",
    "def pathlength_if_connected(my_nw, my_o, my_d):\n",
    "    try:\n",
    "        return(nx.dijkstra_path_length(my_nw, my_o, my_d, weight = \"length\"))\n",
    "    except:\n",
    "        return(math.inf)\n",
    "\n",
    "def extract_coords_from_linestring(linestring):\n",
    "    # Extract coordinates using regex\n",
    "    matches = re.findall(r'(\\d+\\.\\d+) (\\d+\\.\\d+)', linestring)\n",
    "    return [(float(y), float(x)) for x, y in matches]\n",
    "\n",
    "def get_path_coords(my_path, my_coorddict):\n",
    "    pathcoords = []\n",
    "    for edge_id in my_path:\n",
    "        sorted_edge_id = tuple(sorted(edge_id))\n",
    "        if sorted_edge_id in my_coorddict:\n",
    "            linestring = my_coorddict[sorted_edge_id]\n",
    "            edge_coords = extract_coords_from_linestring(linestring)\n",
    "            pathcoords.append(edge_coords)\n",
    "        else:\n",
    "            print(f\"Key {sorted_edge_id} not found in my_coorddict!\")\n",
    "    return pathcoords\n",
    "\n",
    "# Identify all the gaps:\n",
    "\n",
    "# shortest_path_list = list of shortest paths for all possible contact-to-contact node combinations\n",
    "\n",
    "shortest_path_list = []\n",
    "\n",
    "if not os.path.exists(\"../data/chunks\"):\n",
    "    os.mkdir(\"../data/chunks\")\n",
    "\n",
    "# ALL CONTACT NODES FROM THE NETWORK\n",
    "nodestack = [node.index for node in h.vs()]\n",
    "\n",
    "count = 0\n",
    "\n",
    "while nodestack:\n",
    "    \n",
    "    node = nodestack.pop()\n",
    "    \n",
    "    # ADDING SHORTEST PATHS FROM CURRENT NODE TO ALL OTHER NODES REMAINING IN THE STACK \n",
    "    shortest_path_list = shortest_path_list + h.get_shortest_paths(node, to=nodestack, weights=\"length\", mode=\"out\", output = \"epath\")\n",
    "    \n",
    "    # CHUNKWISE SAVING OF RESULTS (TO BE READ IN LATER)\n",
    "    if len(shortest_path_list) >= 2*10**5:\n",
    "        with open(\"../data/chunks/c\" + str(count) + \".pickle\", 'wb') as handle:\n",
    "            pkl.dump(shortest_path_list, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "        del(shortest_path_list)\n",
    "        count += 1\n",
    "        shortest_path_list = []\n",
    "\n",
    "# SAVING LAST CHUNK (WITH LEN < 2*10**5)\n",
    "with open(\"../data/c\" + str(count) + \".pickle\", 'wb') as handle:\n",
    "    pkl.dump(shortest_path_list, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "del(shortest_path_list)\n",
    "\n",
    "### LOOP THROUGH ALL SHORTEST PATHS; KEEP ONLY THE PATHS THAT CONSIST ONLY OF HIGH STRESS LINKS\n",
    "\n",
    "# cs: set of car edges\n",
    "cs = set()\n",
    "for edge in eids_conv[\"ig\"]:\n",
    "    if h.es[edge][\"category_edge\"] == \"high\":\n",
    "        cs.add(edge)\n",
    "\n",
    "mygaps = []\n",
    "    \n",
    "# CHUNKWISE:\n",
    "\n",
    "mychunks = [\"../data/chunks/\" + filename for filename in os.listdir(\"../data/chunks/\")]\n",
    "\n",
    "for chunk in mychunks:\n",
    "    \n",
    "    with open(chunk, 'rb') as f:\n",
    "        pathlist = pkl.load(f)\n",
    "\n",
    "    # adding the item to the gaplist only if it consists of only-highstress-edges\n",
    "    gaplist = [item for item in pathlist if set(item).issubset(cs)]\n",
    "\n",
    "    mygaps = mygaps + gaplist\n",
    "    \n",
    "    del(gaplist, pathlist)\n",
    "    \n",
    "print(len(mygaps), \"gaps found\")\n",
    "\n",
    "# remove chunks (not needed anymore)\n",
    "for chunk in mychunks:\n",
    "    os.remove(chunk)\n",
    "os.rmdir(\"../data/chunks\")\n",
    "\n",
    "# CONVERT GAPS LIST TO DF AND ADD LENGTH, ORIGIN, DESTINATION\n",
    "\n",
    "# to df\n",
    "mygaps = pd.DataFrame({\"path\": mygaps})\n",
    "\n",
    "# add length\n",
    "mygaps[\"length\"] = mygaps.apply(lambda x: np.sum([h.es[e][\"length\"] for e in x.path]), axis = 1)\n",
    "\n",
    "# add path in nx edge id\n",
    "mygaps[\"path_nx\"] = mygaps.apply(lambda x: \n",
    "                                 [tuple(sorted(literal_eval(h.es[edge][\"edge_id\"]))) for edge in x.path], \n",
    "                                 axis = 1)\n",
    "\n",
    "\n",
    "# add origin and destination nodes\n",
    "# (separate procedure for gaps with edgenumber (enr) == 1 vs. gaps with enr > 1)\n",
    "mygaps[\"enr\"] = mygaps.apply(lambda x: len(x.path), axis = 1)\n",
    "mygaps[\"o_nx\"] = None\n",
    "mygaps[\"d_nx\"] = None\n",
    "mygaps.loc[mygaps[\"enr\"]==1, \"o_nx\"] = mygaps[mygaps[\"enr\"] == 1].apply(lambda x: x.path_nx[0][0], axis = 1)\n",
    "mygaps.loc[mygaps[\"enr\"]==1, \"d_nx\"] = mygaps[mygaps[\"enr\"] == 1].apply(lambda x: x.path_nx[0][1], axis = 1)\n",
    "mygaps.loc[mygaps[\"enr\"]!=1, \"o_nx\"] = mygaps[mygaps[\"enr\"]!=1].apply(lambda x: set(x.path_nx[0]).difference(x.path_nx[1]).pop(), axis = 1)\n",
    "mygaps.loc[mygaps[\"enr\"]!=1, \"d_nx\"] = mygaps[mygaps[\"enr\"]!=1].apply(lambda x: set(x.path_nx[-1]).difference(x.path_nx[-2]).pop(), axis = 1)\n",
    "mygaps.drop(columns = \"enr\", inplace = True)\n",
    "\n",
    "# add coordinates for  plotting\n",
    "mygaps[\"gapcoord\"] = mygaps.apply(lambda x: get_path_coords(x.path_nx, ced), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             length  length_b   detour\n",
      "count  14437.000000   14437.0  14437.0\n",
      "mean    3420.104838       inf      inf\n",
      "std     2394.433034       NaN      NaN\n",
      "min        4.631000       inf      inf\n",
      "25%     1469.910000       NaN      NaN\n",
      "50%     2888.456000       NaN      NaN\n",
      "75%     5115.456000       NaN      NaN\n",
      "max    12763.125000       inf      inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonardo/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:4009: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/Users/leonardo/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:4009: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    }
   ],
   "source": [
    "#Discard \"parallel paths\" (gaps connected on low stress network with a detour factor below d_min)\n",
    "\n",
    "D_min = 1.5 # set minimum detour factor for path to count as gap\n",
    "\n",
    "# compute detour factor on bike network\n",
    "mygaps[\"length_b\"] = mygaps.apply(lambda x: pathlength_if_connected(banw, x.o_nx, x.d_nx), axis = 1)\n",
    "mygaps[\"detour\"] = mygaps[\"length_b\"]/mygaps[\"length\"]\n",
    "mygaps = mygaps[mygaps[\"detour\"]>=D_min].reset_index(drop = True)\n",
    "print(mygaps.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prioritize\n",
    "# compute benefit metric B_star(g)\n",
    "mygaps[\"B_star\"] = mygaps.apply(lambda x: \n",
    "                                        np.sum([ebc.loc[ebc[\"edge_ig\"]==i, \"ebc_lambda\"] * \\\n",
    "                                                h.es[i][\"length\"] \\\n",
    "                                                for i in x.path]), \n",
    "                                        axis = 1)\n",
    "mygaps[\"B\"] = mygaps[\"B_star\"] / mygaps[\"length\"] # B(g) normed to length\n",
    "\n",
    "# sort gaps by descending benefit metric\n",
    "mygaps = mygaps.sort_values(by = \"B\", ascending = False).reset_index(drop = True)\n",
    "\n",
    "mygaps.to_pickle(\"../data/mygaps.pickle\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
