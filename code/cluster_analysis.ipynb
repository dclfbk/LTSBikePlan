{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LTS Cluster Analysis:\n",
    "## Use clustering algorithms to identify clusters of high-stress in the network.\n",
    "## The clusters represent areas where there's a high level of traffic stress. \n",
    "# If you see many clusters close to each other or a large cluster, it indicates that particular region experiences high stress.\n",
    "# import osmnx as ox\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import DBSCAN,OPTICS\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "# import matplotlib.cm as cm\n",
    "\n",
    "# base_path = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/images\"\n",
    "# city_name = \"Trento\"\n",
    "\n",
    "# # Create the path for the new folder\n",
    "# city_folder_path = os.path.join(base_path, city_name)\n",
    "\n",
    "# # Create the folder if it doesn't exist\n",
    "# if not os.path.exists(city_folder_path):\n",
    "#     os.makedirs(city_folder_path)\n",
    "\n",
    "# # Load data\n",
    "# filepath = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/Trento_lts.graphml\"\n",
    "# G_lts = ox.load_graphml(filepath)\n",
    "# G_lts = ox.project_graph(G_lts, to_crs='EPSG:4326')\n",
    "# crs = G_lts.graph['crs']\n",
    "\n",
    "# def plot_k_distance_graph(features, k=2):\n",
    "#     \"\"\"Plot the k-distance graph.\"\"\"\n",
    "#     # Fit the Nearest Neighbors model\n",
    "#     neigh = NearestNeighbors(n_neighbors=k)\n",
    "#     nbrs = neigh.fit(features)\n",
    "#     distances, _ = nbrs.kneighbors(features)\n",
    "    \n",
    "#     # Sort the distances\n",
    "#     sorted_distances = np.sort(distances, axis=0)[:, 1]\n",
    "    \n",
    "#     # Setup the plot aesthetics\n",
    "#     # sns.set_style('darkgrid')\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "    \n",
    "#     # Plot the k-distance graph\n",
    "#     plt.plot(sorted_distances, lw=2)\n",
    "#     plt.title('K-distance Graph', fontsize=16, fontweight='bold')\n",
    "#     plt.xlabel('Points sorted according to distance of k-th nearest neighbor', fontsize=14)\n",
    "#     plt.ylabel(f'Distance to {k}-th nearest neighbor', fontsize=14)\n",
    "#     plt.tight_layout()\n",
    "#     plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     plt.show()\n",
    "\n",
    "# def cluster_nodes_by_stress(G):\n",
    "#     \"\"\"Cluster nodes based on stress.\"\"\"\n",
    "#     # Extract data\n",
    "#     node_data = [\n",
    "#         {'id': node, 'y': float(data['y']), 'x': float(data['x']), 'lts': int(data['lts'])} \n",
    "#         for node, data in G.nodes(data=True) if 'lts' in data and int(data[\"lts\"]) == 4\n",
    "#     ]\n",
    "#     features = np.array([(data['y'], data['x']) for data in node_data])\n",
    "    \n",
    "#     # Determine eps using k-distance graph\n",
    "#     plot_k_distance_graph(features)\n",
    "    \n",
    "#     eps = float(input(\"Based on the elbow in the plot, enter the value for eps: \"))\n",
    "    \n",
    "#     # Setting min_samples\n",
    "#     #D = features.shape[1]  # number of features, or dimensions\n",
    "#     #cmin_samples = D + 1\n",
    "#     #density_factor = 2  # this can be adjusted based on the desired density\n",
    "#     #min_samples = base_min_samples * density_factor\n",
    "#     min_samples = 15\n",
    "\n",
    "#     # DBSCAN Clustering\n",
    "#     db = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
    "#     labels = db.labels_\n",
    "    \n",
    "#     # Add cluster labels back to nodes\n",
    "#     for idx, data in enumerate(node_data):\n",
    "#         node = data['id']\n",
    "#         G.nodes[node]['cluster'] = labels[idx]\n",
    "    \n",
    "#     return G, labels, features\n",
    "\n",
    "\n",
    "# def plot_clusters(G, save_path=None):\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "#     # Set the background color of the figure and axis\n",
    "#     fig.patch.set_facecolor('white')\n",
    "#     ax.set_facecolor('white')\n",
    "        \n",
    "#     # Filter out nodes that don't have the 'cluster' attribute or are labeled as outliers (-1)\n",
    "#     filtered_nodes = [node for node in G.nodes() if 'cluster' in G.nodes[node] and G.nodes[node]['cluster'] != -1]\n",
    "    \n",
    "#     # Get the 'cluster' attribute value for these nodes\n",
    "#     clusters = [G.nodes[node]['cluster'] for node in filtered_nodes]\n",
    "    \n",
    "#     # Create a custom color map using a list of colors\n",
    "#     custom_cmap = plt.cm.get_cmap('tab10', len(np.unique(clusters)))\n",
    "\n",
    "#     # Map the cluster labels to the colors\n",
    "#     node_colors = [custom_cmap(cluster) for cluster in clusters]\n",
    "    \n",
    "#     # Plot the subgraph of nodes with the 'cluster' attribute and aren't outliers\n",
    "#     graph = G.subgraph(filtered_nodes)\n",
    "#     ox.plot_graph(graph, node_color=node_colors, edge_linewidth=1.0, node_size=50, show=False, ax=ax)\n",
    "\n",
    "#     plt.title('LTS Cluster Analysis')\n",
    "#     if save_path:\n",
    "#         plt.savefig(os.path.join(save_path, \"lts_cluster.pdf\"))\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Use:\n",
    "# cluster_nodes, labels, features = cluster_nodes_by_stress(G_lts)\n",
    "# plot_clusters(cluster_nodes, save_path=city_folder_path)\n",
    "\n",
    "# # Check noise labels exclusion:\n",
    "# noise_proportion = (labels == -1).sum() / len(labels)\n",
    "# print(noise_proportion)\n",
    "\n",
    "# # Exclude noise labels before calculating silhouette score\n",
    "# non_noise_indices = labels != -1\n",
    "\n",
    "# # Compute silhouette score excluding noise points\n",
    "# sil_score = silhouette_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# db_score = davies_bouldin_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# ch_score = calinski_harabasz_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# print(f\"Silhouette Score - DBSCAN: {sil_score}\")\n",
    "# print(f'Davies-Bouldin Index - DBSCAN: {db_score}')\n",
    "# print(f'Calinski-Harabasz Score - DBSCAN: {ch_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN,OPTICS\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "## LTS Cluster Analysis:\n",
    "## Use clustering algorithms to identify clusters of high-stress in the network.\n",
    "## The clusters represent areas where there's a high level of traffic stress. \n",
    "# If you see many clusters close to each other or a large cluster, it indicates that particular region experiences high stress.\n",
    "\n",
    "base_path = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/images\"\n",
    "city_name = \"Bolzano\"\n",
    "\n",
    "# Create the path for the new folder\n",
    "city_folder_path = os.path.join(base_path, city_name)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(city_folder_path):\n",
    "    os.makedirs(city_folder_path)\n",
    "\n",
    "# Load data\n",
    "filepath = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/Bolzano_lts.graphml\"\n",
    "G_lts = ox.load_graphml(filepath)\n",
    "G_lts = ox.project_graph(G_lts, to_crs='EPSG:4326')\n",
    "crs = G_lts.graph['crs']     \n",
    "\n",
    "#DBSCAN case\n",
    "\n",
    "node_data = [\n",
    "        {'id': node, 'y': float(data['y']), 'x': float(data['x']), 'lts': int(data['lts'])} \n",
    "        for node, data in G_lts.nodes(data=True) if 'lts' in data and int(data['lts']) == 4\n",
    "    ]\n",
    "\n",
    "# Convert node data to DataFrame\n",
    "node_df = pd.DataFrame(node_data)\n",
    "\n",
    "# Create a GeoDataFrame for spatial operations\n",
    "geometry = [Point(xy) for xy in zip(node_df.x, node_df.y)]\n",
    "geo_df = GeoDataFrame(node_df, crs=crs, geometry=geometry)\n",
    "\n",
    "# Function to plot k-distance graph\n",
    "def plot_k_distance_graph(features, k=2):\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    nbrs = neigh.fit(features)\n",
    "    distances, _ = nbrs.kneighbors(features)\n",
    "    sorted_distances = np.sort(distances, axis=0)[:, 1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sorted_distances, lw=2)\n",
    "    plt.title('K-distance Graph', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Points sorted according to distance of k-th nearest neighbor', fontsize=14)\n",
    "    plt.ylabel(f'Distance to {k}-th nearest neighbor', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Feature matrix for clustering\n",
    "X = geo_df[['x', 'y', 'lts']]  # Adjust features as needed\n",
    "\n",
    "# Determine eps using k-distance graph\n",
    "plot_k_distance_graph(X)\n",
    "\n",
    "eps = float(input(\"Based on the elbow in the plot, enter the value for eps: \"))\n",
    "min_samples = 5\n",
    "\n",
    "# Clustering (example using DBSCAN)\n",
    "dbscan = DBSCAN(eps, min_samples=15)  # Adjust parameters as needed\n",
    "geo_df['cluster'] = dbscan.fit_predict(X)\n",
    "clustered_geo_df = geo_df[geo_df['cluster'] != -1]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(clustered_geo_df['x'], clustered_geo_df['y'], c=clustered_geo_df['cluster'], cmap=cm.rainbow, alpha=0.7)\n",
    "plt.title(f'Clustered Intersections in {city_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig(os.path.join(city_folder_path, \"dbscan_lts_cluster.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# Ensure the GeoDataFrame is in the same CRS as the OSMnx graph\n",
    "clustered_geo_df = clustered_geo_df.to_crs(G_lts.graph['crs'])\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = ox.plot_graph(G_lts, show=False, close=False)\n",
    "\n",
    "# Plot the clustered points\n",
    "scatter = ax.scatter(clustered_geo_df['geometry'].x, clustered_geo_df['geometry'].y, \n",
    "                     c=clustered_geo_df['cluster'], cmap=cm.rainbow, alpha=0.7)\n",
    "\n",
    "# Optional: Add a color bar\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Clustered Intersections in {city_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig(os.path.join(city_folder_path, \"dbscan_lts_cluster_geo.pdf\"))\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Ensure to exclude noise points (label -1) before computing the scores\n",
    "filtered_labels = geo_df[geo_df['cluster'] != -1]['cluster']\n",
    "filtered_features = geo_df[geo_df['cluster'] != -1][['x', 'y', 'lts']]\n",
    "\n",
    "# Silhouette Score\n",
    "if len(np.unique(filtered_labels)) > 1:  # Requires at least 2 clusters to compute\n",
    "    silhouette = silhouette_score(filtered_features, filtered_labels)\n",
    "    print(f'Silhouette Score: {silhouette}')\n",
    "else:\n",
    "    print(\"Silhouette Score cannot be computed with less than 2 clusters.\")\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "davies_bouldin = davies_bouldin_score(filtered_features, filtered_labels)\n",
    "print(f'Davies-Bouldin Score: {davies_bouldin}')\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "calinski_harabasz = calinski_harabasz_score(filtered_features, filtered_labels)\n",
    "print(f'Calinski-Harabasz Score: {calinski_harabasz}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HDBSCAN cluster algorithm \n",
    "\n",
    "# import hdbscan\n",
    "\n",
    "# def cluster_nodes_by_stress_hdbscan(G):\n",
    "#     # Extract data\n",
    "#     node_data = [\n",
    "#         {'id': node, 'y': float(data['y']), 'x': float(data['x']), 'lts': int(data['lts'])} \n",
    "#         for node, data in G.nodes(data=True) if 'lts' in data and int(data['lts']) == 4\n",
    "#     ]\n",
    "#     features = np.array([(data['y'], data['x']) for data in node_data])\n",
    "\n",
    "#     # Setting min_cluster_size for HDBSCAN\n",
    "#     min_cluster_size = 4\n",
    "\n",
    "#     # HDBSCAN Clustering\n",
    "#     clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "#     labels = clusterer.fit_predict(features)\n",
    "\n",
    "#     # Add cluster labels back to nodes\n",
    "#     for idx, data in enumerate(node_data):\n",
    "#         node = data['id']\n",
    "#         G.nodes[node]['cluster'] = labels[idx]\n",
    "    \n",
    "#     return G, labels, features\n",
    "\n",
    "# def plot_clusters(G, save_path=None):\n",
    "#     fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "#     # Set the background color of the figure and axis\n",
    "#     fig.patch.set_facecolor('white')\n",
    "#     ax.set_facecolor('white')\n",
    "        \n",
    "#     # Filter out nodes that don't have the 'cluster' attribute or are labeled as outliers (-1)\n",
    "#     filtered_nodes = [node for node in G.nodes() if 'cluster' in G.nodes[node] and G.nodes[node]['cluster'] != -1]\n",
    "    \n",
    "#     # Get the 'cluster' attribute value for these nodes\n",
    "#     clusters = [G.nodes[node]['cluster'] for node in filtered_nodes]\n",
    "    \n",
    "#     # Create a custom color map using a list of colors\n",
    "#     custom_cmap = plt.cm.get_cmap('tab10', len(np.unique(clusters)))\n",
    "\n",
    "#     # Map the cluster labels to the colors\n",
    "#     node_colors = [custom_cmap(cluster) for cluster in clusters]\n",
    "    \n",
    "#     # Plot the subgraph of nodes with the 'cluster' attribute and aren't outliers\n",
    "#     graph = G.subgraph(filtered_nodes)\n",
    "#     ox.plot_graph(graph, node_color=node_colors, edge_linewidth=1.0, node_size=50, show=False, ax=ax)\n",
    "#     plt.title('LTS HDBSCAN Cluster Analysis')\n",
    "#     if save_path:\n",
    "#         plt.savefig(os.path.join(save_path, \"lts_hdbscan_cluster.pdf\"))\n",
    "#     plt.show()\n",
    "\n",
    "# # Use:\n",
    "# cluster_nodes, labels, features = cluster_nodes_by_stress_hdbscan(G_lts)\n",
    "# plot_clusters(cluster_nodes, city_folder_path)\n",
    "\n",
    "# # Check noise labels exclusion:\n",
    "# noise_proportion = (labels == -1).sum() / len(labels)\n",
    "# print(noise_proportion)\n",
    "\n",
    "# # Exclude noise labels before calculating silhouette score\n",
    "# non_noise_indices = labels != -1\n",
    "\n",
    "# # Compute silhouette score excluding noise points\n",
    "# sil_score = silhouette_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# db_score = davies_bouldin_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# ch_score = calinski_harabasz_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# print(f\"Silhouette Score - HDBSCAN: {sil_score}\")\n",
    "# print(f'Davies-Bouldin Index - HDBSCAN: {db_score}')\n",
    "# print(f'Calinski-Harabasz Score - HDBSCAN: {ch_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN case\n",
    "import hdbscan\n",
    "# Convert node data to DataFrame\n",
    "node_df = pd.DataFrame(node_data)\n",
    "\n",
    "# Create a GeoDataFrame for spatial operations\n",
    "geometry = [Point(xy) for xy in zip(node_df.x, node_df.y)]\n",
    "geo_df = GeoDataFrame(node_df, crs=crs, geometry=geometry)\n",
    "\n",
    "# Feature matrix for clustering\n",
    "X = geo_df[['x', 'y','lts']] \n",
    "\n",
    "# Clustering using HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=15, min_samples=5)\n",
    "geo_df['cluster'] = clusterer.fit_predict(X)\n",
    "clustered_geo_df = geo_df[geo_df['cluster'] != -1]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(clustered_geo_df['x'], clustered_geo_df['y'], c=clustered_geo_df['cluster'], cmap=cm.rainbow, alpha=0.7)\n",
    "plt.title(f'Clustered Intersections in {city_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig(os.path.join(city_folder_path, \"hdbscan_lts_cluster.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# Ensure the GeoDataFrame is in the same CRS as the OSMnx graph\n",
    "clustered_geo_df = clustered_geo_df.to_crs(G_lts.graph['crs'])\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = ox.plot_graph(G_lts, show=False, close=False)\n",
    "\n",
    "# Plot the clustered points\n",
    "scatter = ax.scatter(clustered_geo_df['geometry'].x, clustered_geo_df['geometry'].y, \n",
    "                     c=clustered_geo_df['cluster'], cmap=cm.rainbow, alpha=0.7)\n",
    "\n",
    "# Optional: Add a color bar\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Clustered Intersections in {city_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig(os.path.join(city_folder_path, \"hdbscan_lts_cluster_geo.pdf\"))\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Ensure to exclude noise points (label -1) before computing the scores\n",
    "filtered_labels = geo_df[geo_df['cluster'] != -1]['cluster']\n",
    "filtered_features = geo_df[geo_df['cluster'] != -1][['x', 'y', 'lts']]\n",
    "\n",
    "# Silhouette Score\n",
    "if len(np.unique(filtered_labels)) > 1:  # Requires at least 2 clusters to compute\n",
    "    silhouette = silhouette_score(filtered_features, filtered_labels)\n",
    "    print(f'Silhouette Score: {silhouette}')\n",
    "else:\n",
    "    print(\"Silhouette Score cannot be computed with less than 2 clusters.\")\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "davies_bouldin = davies_bouldin_score(filtered_features, filtered_labels)\n",
    "print(f'Davies-Bouldin Score: {davies_bouldin}')\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "calinski_harabasz = calinski_harabasz_score(filtered_features, filtered_labels)\n",
    "print(f'Calinski-Harabasz Score: {calinski_harabasz}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cluster_nodes_by_stress_optics(G):\n",
    "#     # Extract data\n",
    "#     node_data = [\n",
    "#         {'id': node, 'y': float(data['y']), 'x': float(data['x']), 'lts': int(data['lts'])} \n",
    "#         for node, data in G.nodes(data=True) if 'lts' in data and int(data['lts']) == 4\n",
    "#     ]\n",
    "#     features = np.array([(data['y'], data['x']) for data in node_data])\n",
    "\n",
    "#     # OPTICS Clustering\n",
    "#     clusterer = OPTICS(min_samples=7) \n",
    "#     labels = clusterer.fit_predict(features)\n",
    "\n",
    "#     # Add cluster labels back to nodes\n",
    "#     for idx, data in enumerate(node_data):\n",
    "#         node = data['id']\n",
    "#         G.nodes[node]['cluster'] = labels[idx]\n",
    "    \n",
    "#     return G, labels, features\n",
    "\n",
    "# def plot_clusters(G,save_path=None):\n",
    "#     fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "#     # Set the background color of the figure and axis\n",
    "#     fig.patch.set_facecolor('white')\n",
    "#     ax.set_facecolor('white')\n",
    "        \n",
    "#     # Filter out nodes that don't have the 'cluster' attribute or are labeled as outliers (-1)\n",
    "#     filtered_nodes = [node for node in G.nodes() if 'cluster' in G.nodes[node] and G.nodes[node]['cluster'] != -1]\n",
    "    \n",
    "#     # Get the 'cluster' attribute value for these nodes\n",
    "#     clusters = [G.nodes[node]['cluster'] for node in filtered_nodes]\n",
    "    \n",
    "#     # Create a custom color map using a list of colors\n",
    "#     custom_cmap = plt.cm.get_cmap('tab10', len(np.unique(clusters)))\n",
    "\n",
    "#     # Map the cluster labels to the colors\n",
    "#     node_colors = [custom_cmap(cluster) for cluster in clusters]\n",
    "    \n",
    "#     # Plot the subgraph of nodes with the 'cluster' attribute and aren't outliers\n",
    "#     graph = G.subgraph(filtered_nodes)\n",
    "#     ox.plot_graph(graph, node_color=node_colors, edge_linewidth=1.0, node_size=50, show=False, ax=ax)\n",
    "\n",
    "#     plt.title('LTS Cluster Analysis')\n",
    "#     if save_path:\n",
    "#         plt.savefig(os.path.join(save_path, \"lts_cluster_analysis_result.pdf\"))\n",
    "#     plt.show()\n",
    "\n",
    "# # Use:\n",
    "# cluster_nodes, labels, features = cluster_nodes_by_stress_optics(G_lts)\n",
    "# plot_clusters(cluster_nodes, city_folder_path)\n",
    "\n",
    "# # Check noise labels exclusion:\n",
    "# noise_proportion = (labels == -1).sum() / len(labels)\n",
    "# print(noise_proportion)\n",
    "\n",
    "# # Exclude noise labels before calculating silhouette score\n",
    "# non_noise_indices = labels != -1\n",
    "\n",
    "# # Compute silhouette score excluding noise points\n",
    "# sil_score = silhouette_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# db_score = davies_bouldin_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# ch_score = calinski_harabasz_score(features[non_noise_indices], labels[non_noise_indices])\n",
    "# print(f\"Silhouette Score: {sil_score}\")\n",
    "# print(f'Davies-Bouldin Index: {db_score}')\n",
    "# print(f'Calinski-Harabasz Score: {ch_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert node data to DataFrame\n",
    "node_df = pd.DataFrame(node_data)\n",
    "\n",
    "# Create a GeoDataFrame for spatial operations\n",
    "geometry = [Point(xy) for xy in zip(node_df.x, node_df.y)]\n",
    "geo_df = GeoDataFrame(node_df, crs=crs, geometry=geometry)\n",
    "\n",
    "# Feature matrix for clustering\n",
    "X = geo_df[['x', 'y', 'lts']]  # Adjust features as needed\n",
    "\n",
    "# Clustering using OPTICS\n",
    "optics_clusterer = OPTICS(min_samples=15, xi=0.10, min_cluster_size=5)  # Adjust parameters as needed\n",
    "geo_df['cluster'] = optics_clusterer.fit_predict(X)\n",
    "clustered_geo_df = geo_df[geo_df['cluster'] != -1]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(clustered_geo_df['x'], clustered_geo_df['y'], c=clustered_geo_df['cluster'], cmap=cm.rainbow, alpha=0.7)\n",
    "plt.title(f'Clustered Intersections in {city_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig(os.path.join(city_folder_path, \"optics_lts_cluster.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# Ensure the GeoDataFrame is in the same CRS as the OSMnx graph\n",
    "clustered_geo_df = clustered_geo_df.to_crs(G_lts.graph['crs'])\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = ox.plot_graph(G_lts, show=False, close=False)\n",
    "\n",
    "# Plot the clustered points\n",
    "scatter = ax.scatter(clustered_geo_df['geometry'].x, clustered_geo_df['geometry'].y, \n",
    "                     c=clustered_geo_df['cluster'], cmap=cm.rainbow, alpha=0.7)\n",
    "\n",
    "# Optional: Add a color bar\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Clustered Intersections in {city_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig(os.path.join(city_folder_path, \"optics_lts_cluster_geo.pdf\"))\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Ensure to exclude noise points (label -1) before computing the scores\n",
    "filtered_labels = geo_df[geo_df['cluster'] != -1]['cluster']\n",
    "filtered_features = geo_df[geo_df['cluster'] != -1][['x', 'y', 'lts']]\n",
    "\n",
    "# Silhouette Score\n",
    "if len(np.unique(filtered_labels)) > 1:  # Requires at least 2 clusters to compute\n",
    "    silhouette = silhouette_score(filtered_features, filtered_labels)\n",
    "    print(f'Silhouette Score: {silhouette}')\n",
    "else:\n",
    "    print(\"Silhouette Score cannot be computed with less than 2 clusters.\")\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "davies_bouldin = davies_bouldin_score(filtered_features, filtered_labels)\n",
    "print(f'Davies-Bouldin Score: {davies_bouldin}')\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "calinski_harabasz = calinski_harabasz_score(filtered_features, filtered_labels)\n",
    "print(f'Calinski-Harabasz Score: {calinski_harabasz}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
