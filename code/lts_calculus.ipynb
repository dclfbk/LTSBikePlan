{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T14:54:41.786676Z",
     "iopub.status.busy": "2024-01-08T14:54:41.786153Z",
     "iopub.status.idle": "2024-01-08T14:54:43.144638Z",
     "shell.execute_reply": "2024-01-08T14:54:43.144330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of gdf edges: (7736, 22)\n",
      "Index(['osmid', 'reversed', 'name', 'oneway', 'length', 'bridge', 'maxspeed',\n",
      "       'tunnel', 'highway', 'ref', 'lanes', 'junction', 'access', 'service',\n",
      "       'width', 'landuse', 'est_width', 'context', 'group', 'slope',\n",
      "       'slope_class', 'geometry'],\n",
      "      dtype='object')\n",
      "The shape of gdf edges allowed: (7720, 23)\n",
      "The shape of gdf edges not allowed: (16, 23)\n",
      "The shape of separated edges: (1638, 24)\n",
      "The shape of unseparated edges: (6082, 22)\n",
      "Empty GeoDataFrame\n",
      "Columns: [osmid, reversed, name, oneway, length, bridge, maxspeed, tunnel, highway, ref, lanes, junction, access, service, width, landuse, est_width, context, group, slope, slope_class, geometry]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 22 columns]\n",
      "The shape of analyze lanes: (0, 22)\n",
      "The shape of no lane: (6082, 22)\n",
      "The shape of parking_detected: (0, 22)\n",
      "The shape of parking no-detected: (0, 22)\n",
      "The shape of lts_no_lane: (6082, 26)\n",
      "The shape of all_lts: (7736, 26)\n",
      "Index(['osmid', 'reversed', 'name', 'oneway', 'length', 'bridge', 'maxspeed',\n",
      "       'tunnel', 'highway', 'ref', 'lanes', 'junction', 'access', 'service',\n",
      "       'width', 'landuse', 'est_width', 'context', 'group', 'slope',\n",
      "       'slope_class', 'geometry', 'rule', 'lts', 'lanes_assumed',\n",
      "       'maxspeed_assumed', 'message', 'short_message'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "###Analyze LTS for edges\n",
    "#The process is divided in different steps:\n",
    "# 1) biking allowed, not allowed\n",
    "# 2) check if there are separated paths and assign lowest lst value\n",
    "# 3) check for separated paths and unseparated\n",
    "# 4) check the presence of bike lanes in the unseparated scenario\n",
    "# 5) check presence or not of parking in bike lanes\n",
    "# 6) mixed traffic analyisis\n",
    "from ltsfunctions import BikePathAnalysis\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import osmnx as ox\n",
    "import os\n",
    "\n",
    "# Load the GeoDataFrames from the specified path\n",
    "pickle_path = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/gdf_data.pkl\"\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    gdf_nodes, gdf_edges, city = pickle.load(f)\n",
    "\n",
    "# Start by finding where biking is allowed and get edges where biking is not *not* allowed.\n",
    "print(\"The shape of gdf edges:\", gdf_edges.shape)\n",
    "print(gdf_edges.columns)\n",
    "gdf_allowed, gdf_not_allowed = BikePathAnalysis.biking_permitted(gdf_edges)\n",
    "\n",
    "print(\"The shape of gdf edges allowed:\",gdf_allowed.shape)\n",
    "print(\"The shape of gdf edges not allowed:\",gdf_not_allowed.shape)\n",
    "\n",
    "# check for separated path\n",
    "separated_edges, unseparated_edges = BikePathAnalysis.is_separated_path(gdf_allowed)\n",
    "# assign separated ways lts = 1\n",
    "separated_edges = separated_edges.copy()\n",
    "separated_edges.loc[:, 'lts'] = 1\n",
    "print(\"The shape of separated edges:\", separated_edges.shape)\n",
    "print(\"The shape of unseparated edges:\", unseparated_edges.shape)\n",
    "\n",
    "#check the presence of bike lane in unseparated paths\n",
    "to_analyze, no_lane = BikePathAnalysis.is_bike_lane(unseparated_edges)\n",
    "print(to_analyze)\n",
    "print(\"The shape of analyze lanes:\",to_analyze.shape)\n",
    "print(\"The shape of no lane:\",no_lane.shape)\n",
    "\n",
    "#check presence of the parking or not\n",
    "parking_detected, parking_not_detected = BikePathAnalysis.parking_present(to_analyze)\n",
    "print(\"The shape of parking_detected:\",parking_detected.shape)\n",
    "print(\"The shape of parking no-detected:\",parking_not_detected.shape)\n",
    "parking_lts = BikePathAnalysis.bike_lane_analysis_with_parking(parking_detected)\n",
    "no_parking_lts = BikePathAnalysis.bike_lane_analysis_without_parking(parking_not_detected)\n",
    "\n",
    "# Next - mixed traffic analysis\n",
    "lts_no_lane = BikePathAnalysis.mixed_traffic(no_lane)\n",
    "print(\"The shape of lts_no_lane:\",lts_no_lane.shape)\n",
    "\n",
    "# final components: lts_no_lane, parking_lts, no_parking_lts, separated_edges should all add up\n",
    "# these should all add up to gdf_allowed\n",
    "# print(gdf_allowed.shape)\n",
    "lts_no_lane.shape[0] + parking_lts.shape[0] + no_parking_lts.shape[0] + separated_edges.shape[0]\n",
    "gdf_not_allowed['lts'] = 0\n",
    "all_lts = pd.concat([separated_edges, parking_lts, no_parking_lts, lts_no_lane, gdf_not_allowed])\n",
    "print(\"The shape of all_lts:\", all_lts.shape)\n",
    "\n",
    "# Apply the slope_penalty function to all_lts\n",
    "all_lts = BikePathAnalysis.slope_penalty(all_lts)\n",
    "\n",
    "# decision rule glossary (taken from Bike Ottawa)\n",
    "# Load the dictionaries from the JSON file\n",
    "with open('LTS_decisionrule_dict.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    rule_message_dict = data['rule_message_dict']\n",
    "    simplified_message_dict = data['simplified_message_dict']\n",
    "\n",
    "# Use the dictionaries in your code\n",
    "all_lts['message'] = all_lts['rule'].map(rule_message_dict)\n",
    "all_lts['short_message'] = all_lts['rule'].map(simplified_message_dict)\n",
    "\n",
    "print(all_lts.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T14:54:43.162539Z",
     "iopub.status.busy": "2024-01-08T14:54:43.162322Z",
     "iopub.status.idle": "2024-01-08T14:54:44.573978Z",
     "shell.execute_reply": "2024-01-08T14:54:44.573617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate node LTS. \n",
    "# - An intersection without either was assigned the highest LTS of its intersecting roads. \n",
    "# - Stop signs reduced an otherwise LTS2 intersection to LTS1. \n",
    "# - A signalized intersection of two lowstress links was assigned LTS1. \n",
    "# - Assigned LTS2 to signalized intersections where a low-stress (LTS1/ 2) link crosses a high-stress (LTS3/4) link. \n",
    "# Apply the function to the dataframe\n",
    "gdf_nodes['lts'], gdf_nodes['message'] = zip(*gdf_nodes.apply(BikePathAnalysis.calculate_lts_nodes, args=(all_lts,), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T14:54:44.575912Z",
     "iopub.status.busy": "2024-01-08T14:54:44.575793Z",
     "iopub.status.idle": "2024-01-08T14:54:45.994625Z",
     "shell.execute_reply": "2024-01-08T14:54:45.994313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSMID column successfully handled!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xml.etree.ElementTree as ET\n",
    "import uuid\n",
    "\n",
    "def save_and_correct_graphml(G, filepath):\n",
    "    # Temporarily save the graph to a .graphml file\n",
    "    temp_path = filepath + \"_temp.graphml\"\n",
    "    ox.save_graphml(G, temp_path)\n",
    "\n",
    "    # Load the temporary graphml as an xml tree\n",
    "    tree = ET.parse(temp_path)\n",
    "    root = tree.getroot()\n",
    "    ns = {'graphml': 'http://graphml.graphdrawing.org/xmlns'}\n",
    "    \n",
    "    # Iterate through the data elements and handle floats that should be integers\n",
    "    for data in root.findall(\".//graphml:data\", ns):\n",
    "        if data.text and data.text.endswith(\".0\"):  # This will match strings like \"258916000.0\"\n",
    "            try:\n",
    "                integer_value = int(float(data.text))\n",
    "                data.text = str(integer_value)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # If osmid is NaN or missing, generate a unique positive value\n",
    "        if data.text == \"nan\" or data.text is None:\n",
    "            data.text = str(abs(uuid.uuid4().int))\n",
    "\n",
    "    # Remove the namespace prefix\n",
    "    for elem in root.iter():\n",
    "        elem.tag = elem.tag.split('}')[-1]\n",
    "\n",
    "    # Set the correct xmlns attribute for the root element\n",
    "    root.attrib[\"xmlns\"] = \"http://graphml.graphdrawing.org/xmlns\"\n",
    "    if \"xmlns:ns0\" in root.attrib:\n",
    "        del root.attrib[\"xmlns:ns0\"]\n",
    "\n",
    "    # Save the corrected graphml and remove the temporary one\n",
    "    tree.write(filepath, xml_declaration=True, encoding='utf-8', method=\"xml\")\n",
    "    os.remove(temp_path)\n",
    "\n",
    "\n",
    "base_path = \"/Users/leonardo/Desktop/Tesi/LTSBikePlan/data/\"\n",
    "def extract_city(citta):\n",
    "    # Splitting by comma and taking the first part\n",
    "    first_part = citta.split(\",\")[0]\n",
    "\n",
    "    # Handling cases where the city name might have a hyphen (like 'Bolzano - Bozen')\n",
    "    city_name = first_part.split(\"-\")[0].strip()\n",
    "\n",
    "    # Replacing spaces with underscores after handling the hyphen\n",
    "    city_sanitized = city_name.replace(\" \", \"_\")\n",
    "\n",
    "    return city_sanitized\n",
    "\n",
    "# Sanitize the city name\n",
    "city_sanitized = extract_city(city)\n",
    "\n",
    "# Save nodes data\n",
    "gdf_nodes.to_csv(f\"{base_path}{city_sanitized}_gdf_nodes.csv\")\n",
    "\n",
    "# Save a subset of all_lts directly\n",
    "all_lts[['osmid', 'lanes', 'name', 'highway', 'maxspeed', 'geometry', 'length', 'rule', 'lts', 'group', 'slope', 'slope_class',\n",
    "         'lanes_assumed', 'maxspeed_assumed', 'message', 'short_message']].to_csv(f\"{base_path}{city_sanitized}_all_lts.csv\")\n",
    "\n",
    "# Ensure that osmid is numeric\n",
    "all_lts['osmid'] = all_lts['osmid'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert osmid values to avoid scientific notation\n",
    "all_lts['osmid'] = all_lts['osmid'].apply(lambda x: \"{:.0f}\".format(x) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# # Check and notify if conversion was successful\n",
    "if all_lts['osmid'].astype(str).str.contains('e\\+', regex=True).any():\n",
    "    print(f\"OSMID column still contains values in scientific notation format.\")\n",
    "else:\n",
    "    print(\"OSMID column successfully handled!\")\n",
    "\n",
    "# Convert back to GeoDataFrame and set CRS\n",
    "all_lts = gpd.GeoDataFrame(all_lts, geometry='geometry')\n",
    "all_lts.crs = \"EPSG:4326\"\n",
    "\n",
    "# Create the graph\n",
    "G_lts = ox.graph_from_gdfs(gdf_nodes, all_lts[['osmid', 'lanes', 'name', 'highway',  'maxspeed', 'geometry', 'length', 'rule', 'lts', \n",
    "                                               'slope', 'slope_class', 'lanes_assumed', 'maxspeed_assumed', 'message', 'short_message']])\n",
    "\n",
    "# Save the graph using the new function\n",
    "# ox.save_graphml(G_lts, f\"{base_path}{city_sanitized}_lts.graphml\")\n",
    "# Save the graph using the new function\n",
    "save_and_correct_graphml(G_lts, f\"{base_path}{city_sanitized}_lts.graphml\")\n",
    "\n",
    "# Remove the pickle file after processing\n",
    "os.remove(pickle_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
